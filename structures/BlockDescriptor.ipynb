{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7325f9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import struct\n",
    "\n",
    "import math\n",
    "from collections import defaultdict, Counter\n",
    "from typing import List\n",
    "from typing import TextIO, BinaryIO\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ece6436",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlockDescriptorBuilder:\n",
    "    \n",
    "    def __init__(self,path_collection_statistics:str):\n",
    "        #Todo leggersi il file di collection statistic per determinare il numero dopo il quale si va a gestire\n",
    "        #la posting list su pi√π di un blocco.\n",
    "        \n",
    "        self._min_posting_list_size=1024\n",
    "    \n",
    "    def get_number_of_blocks(self,nr_postings:int):\n",
    "        \n",
    "        if (nr_postings<self._min_posting_list_size):\n",
    "            return 1\n",
    "        \n",
    "        #The strategy is to use as default block size the squared root of the length of the posting list\n",
    "        return math.ceil(math.sqrt(nr_postings))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e0949c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlockDescriptor:\n",
    "    \n",
    "    STR_SIZE_BLOCK_DESCRIPTOR='2q 5i'\n",
    "    SIZE_BLOCK_DESCRIPTOR=struct.calcsize(STR_SIZE_BLOCK_DESCRIPTOR)\n",
    "    \n",
    "    offset_doc_ids:int\n",
    "    offset_freqs:int \n",
    "        \n",
    "    nr_postings:int    \n",
    "        \n",
    "    doc_ids_bytes_size:int\n",
    "    freq_bytes_size:int    \n",
    "        \n",
    "    min_doc_id:int\n",
    "    max_doc_id:int\n",
    "        \n",
    "        \n",
    "    def __init__(self,nr_postings:int=0,offset_doc_ids:int=0,offset_freqs:int=0,doc_ids_bytes_size:int=0,freq_bytes_size:int=0,min_doc_id:int=0,max_doc_id:int=0):\n",
    "        \n",
    "        self.nr_postings=nr_postings\n",
    "        \n",
    "        self.offset_doc_ids=offset_doc_ids\n",
    "        self.offset_freqs=offset_freqs\n",
    "        \n",
    "        self.doc_ids_bytes_size=doc_ids_bytes_size\n",
    "        self.freq_bytes_size=freq_bytes_size\n",
    "        \n",
    "        self.min_doc_id=min_doc_id\n",
    "        self.max_doc_id=max_doc_id\n",
    "        \n",
    "        \n",
    "    def write_block_descriptor_on_disk_to_opened_file(self,file:BinaryIO,offset:int=0):\n",
    "        \"\"\"This function writes on a specific position of an opened file a block descriptor .\n",
    "           \n",
    "           Args:\n",
    "               file: the file to store the block descriptor\n",
    "               offset: the position inside the file to store the block descriptor\n",
    "           Returns:\n",
    "               the new offset free position after writing on the file\n",
    "        \"\"\"\n",
    "        file.seek(offset)\n",
    "       \n",
    "        binary_data = struct.pack(self.STR_SIZE_BLOCK_DESCRIPTOR, self.offset_doc_ids,self.offset_freqs,self.nr_postings,\n",
    "                                 self.doc_ids_bytes_size,self.freq_bytes_size,self.min_doc_id,self.max_doc_id)\n",
    "        file.write(binary_data)\n",
    "            \n",
    "        return self.SIZE_BLOCK_DESCRIPTOR+offset\n",
    "    \n",
    "    \n",
    "    def read_block_descriptor_on_disk_from_opened_file(self,file:BinaryIO,offset:int):\n",
    "        \"\"\"This function reads a block descriptor information in a specific position from an opened file.\n",
    "        \n",
    "        Args:\n",
    "            file: the file to read a block descriptor\n",
    "            offset: the position inside the file to read the block descriptor\n",
    "        \n",
    "        Returns:\n",
    "            the offset position after reading\n",
    "            \n",
    "        \"\"\"\n",
    "        file.seek(offset)  \n",
    "        bytesLetti = file.read(self.SIZE_BLOCK_DESCRIPTOR) \n",
    "        \n",
    "        if(not bytesLetti):\n",
    "            return None\n",
    "        \n",
    "        self.offset_doc_ids,self.offset_freqs,self.nr_postings,self.doc_ids_bytes_size,self.freq_bytes_size,self.min_doc_id,self.max_doc_id= struct.unpack(self.STR_SIZE_BLOCK_DESCRIPTOR, bytesLetti)\n",
    "        \n",
    "        return offset+self.SIZE_BLOCK_DESCRIPTOR\n",
    "    \n",
    "    \n",
    "#USED FOR DEBUGGING\n",
    "    \n",
    "    def write_block_descriptor_on_disk(self,file_path:str,offset:int=0):\n",
    "        \"\"\"This function opens a file and writes on a specific position a block descriptor information.\n",
    "            This is used for debug and tests.\n",
    "        \n",
    "            Args:\n",
    "               file_path: the file to store the block descriptor\n",
    "               offset: the position inside the file to store the block descriptor\n",
    "            Returns:\n",
    "                the new offset free position after writing\n",
    "               \n",
    "        \"\"\"\n",
    "        with open(file_path, 'ab') as file:\n",
    "            return self.write_block_descriptor_on_disk_to_opened_file(file,offset)\n",
    "            \n",
    "    def read_block_descriptor_on_disk(self,file_path:str,offset:int):\n",
    "        \"\"\"This function opens a file and reads in a specific position a block descriptor information.\n",
    "            This is used for debug and tests.\n",
    "        \n",
    "            Args:\n",
    "               file_path: the file to read a lexicon row\n",
    "               offset: the position inside the file to read the block descriptor\n",
    "            Returns:\n",
    "                the offset position after reading\n",
    "        \"\"\"\n",
    "        with open(file_path, 'rb') as file:\n",
    "            return self.read_block_descriptor_on_disk_from_opened_file(file,offset) \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7d4df6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a=BlockDescriptor(5,15,31,10,11,1,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ef055a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a.write_block_descriptor_on_disk(\"prova.bin\",0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "128a1b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#b=BlockDescriptor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfafa59e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#b.read_block_descriptor_on_disk(\"prova.bin\",0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
