{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0144940d-2ee7-4d87-a3df-7f36f3f808a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from C:\\Users\\Davide\\IR\\Progetto\\tests\\Structures\\../..\\structures\\Lexicon.ipynb\n",
      "importing Jupyter notebook from C:\\Users\\Davide\\IR\\Progetto\\tests\\Structures\\../..\\structures\\LexiconRow.ipynb\n",
      "importing Jupyter notebook from C:\\Users\\Davide\\IR\\Progetto\\tests\\Structures\\../..\\structures\\DocumentIndex.ipynb\n",
      "importing Jupyter notebook from C:\\Users\\Davide\\IR\\Progetto\\tests\\Structures\\../..\\utilities\\General_Utilities.ipynb\n",
      "importing Jupyter notebook from C:\\Users\\Davide\\IR\\Progetto\\tests\\Structures\\../..\\structures\\DocumentIndexRow.ipynb\n",
      "importing Jupyter notebook from C:\\Users\\Davide\\IR\\Progetto\\tests\\Structures\\../..\\building_data_structures\\CollectionStatistics.ipynb\n",
      "importing Jupyter notebook from C:\\Users\\Davide\\IR\\Progetto\\tests\\Structures\\../..\\pre_processing\\Decompress_collection.ipynb\n",
      "importing Jupyter notebook from C:\\Users\\Davide\\IR\\Progetto\\tests\\Structures\\../..\\pre_processing\\TextProcessor.ipynb\n",
      "importing Jupyter notebook from C:\\Users\\Davide\\IR\\Progetto\\tests\\Structures\\../..\\building_data_structures\\IndexBuilder.ipynb\n",
      "importing Jupyter notebook from C:\\Users\\Davide\\IR\\Progetto\\tests\\Structures\\../..\\structures\\InvertedIndex.ipynb\n",
      "importing Jupyter notebook from C:\\Users\\Davide\\IR\\Progetto\\tests\\Structures\\../..\\utilities\\Compression.ipynb\n",
      "importing Jupyter notebook from C:\\Users\\Davide\\IR\\Progetto\\tests\\Structures\\../..\\structures\\BlockDescriptor.ipynb\n",
      "importing Jupyter notebook from C:\\Users\\Davide\\IR\\Progetto\\tests\\Structures\\../..\\query_processing\\Scoring.ipynb\n"
     ]
    }
   ],
   "source": [
    "#import import_ipynb\n",
    "from collections import OrderedDict\n",
    "from random import randint\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "sys.path.append('../../')  # Go up two folders to the project root\n",
    "\n",
    "from structures.Lexicon import Lexicon\n",
    "from structures.LexiconRow import LexiconRow\n",
    "from pre_processing.Decompress_collection import Collection_Reader\n",
    "from building_data_structures.IndexBuilder import IndexBuilder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5776eff-12be-4b94-8ecc-4b9e371af587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pytest\n",
    "# import ipytest\n",
    "\n",
    "# ipytest.autoconfig()\n",
    "\n",
    "DIR_TEMP_FOLDER=\"TEMP\"\n",
    "DIR_LEXICON=\"LEXICON\"\n",
    "DIR_DOC_INDEX=\"DOC_INDEX\"\n",
    "DIR_INVERTED_INDEX=\"INV_INDEX\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0beaa86c-f753-4721-a348-7ca0d44e6680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.04s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# %%ipytest\n",
    "\n",
    "def test_lexicon_add_term():\n",
    "    capacity = 5\n",
    "    \n",
    "    test_documents=[\"doc0\"+\"\\t\"+\" testterm testterm testterm testterm testterm testterm testterm testterm testterm testterm\",\n",
    "                    \"doc1\"+\"\\t\"+\" term1 rrr\",\n",
    "                    \"doc2\"+\"\\t\"+\" term2 term2\",\n",
    "                    \"doc3\"+\"\\t\"+\" term3 term3 term3\",\n",
    "                    \"doc4\"+\"\\t\"+\" term4 term4 term4 term4\"\n",
    "                   ]\n",
    "    \n",
    "    indexBuilder=IndexBuilder(True,False,Collection_Reader(\"\",-1,-1,False,False,test_documents))\n",
    "    indexBuilder.single_pass_in_memory_indexing(15000000)\n",
    "    indexBuilder.index_merging()\n",
    "    \n",
    "    \n",
    "    \n",
    "    lexicon = Lexicon(capacity,\"../Structures/LEXICON/lexicon.bin\",\"../Structures/DOC_INDEX/collection_statistics.bin\")\n",
    "    assert lexicon.is_empty()\n",
    "    \n",
    "    lex_row = LexiconRow(\"testterm\", 10)\n",
    "    lexicon.add_term(lex_row)\n",
    "\n",
    "    key = \"testterm\".ljust(lex_row.MAX_TERM_LENGTH)\n",
    "\n",
    "    assert len(lexicon._vocabulary) == 1\n",
    "    assert lexicon._vocabulary == lexicon.get_structure()\n",
    "    \n",
    "    assert lexicon.get_terms(key).term == key\n",
    "    assert lexicon.get_terms(key).term == lex_row.term\n",
    "    assert lexicon.get_terms(key).dft == lex_row.dft\n",
    "\n",
    "    assert not lexicon.is_empty()\n",
    "\n",
    "    # Add 100 row to lexicon and test that:\n",
    "    # - size remains lower or equal than 5 all the time\n",
    "    # - structure follow the \"LRU\" cache replacement policy\n",
    "    lexicon.add_term(LexiconRow(\"term1\", 1))\n",
    "    lexicon.add_term(LexiconRow(\"term2\", 2))\n",
    "    lexicon.add_term(LexiconRow(\"term3\", 3))\n",
    "    lexicon.add_term(LexiconRow(\"term4\", 4))\n",
    "    for i in range(5, 100):\n",
    "        random_term = f\"term{i}\"\n",
    "        lex_row = LexiconRow(random_term, i)\n",
    "    \n",
    "        lexicon.add_term(lex_row)\n",
    "        assert len(lexicon.get_structure()) <= 5\n",
    "        \n",
    "        counter = capacity - 1\n",
    "        for elem in lexicon.get_structure().values():\n",
    "            assert elem.term == f\"term{int(i - counter)}\".ljust(lex_row.MAX_TERM_LENGTH)\n",
    "            counter = counter - 1   \n",
    "\n",
    "\n",
    "    lexicon.clear_structure()\n",
    "    assert lexicon.is_empty()\n",
    "    \n",
    "    lexicon.close_file()\n",
    "    \n",
    "    if os.path.exists(DIR_LEXICON):\n",
    "        shutil.rmtree(DIR_LEXICON)\n",
    "                \n",
    "    if os.path.exists(DIR_INVERTED_INDEX):\n",
    "        shutil.rmtree(DIR_INVERTED_INDEX)\n",
    "    \n",
    "    if os.path.exists(DIR_DOC_INDEX):\n",
    "        shutil.rmtree(DIR_DOC_INDEX)\n",
    "    \n",
    "    if os.path.exists(DIR_TEMP_FOLDER):\n",
    "        shutil.rmtree(DIR_TEMP_FOLDER)\n",
    "    \n",
    "    test_documents=[\"doc0\"+\"\\t\"+\" aaaaa ttt\",\n",
    "                    \"doc1\"+\"\\t\"+\" bbbbb rrr\",\n",
    "                    \"doc2\"+\"\\t\"+\" ccccc jjj\",\n",
    "                    \"doc3\"+\"\\t\"+\" happiness\"]\n",
    "    \n",
    "    \n",
    "    indexBuilder=IndexBuilder(True,False,Collection_Reader(\"\",-1,-1,False,False,test_documents))\n",
    "    indexBuilder.single_pass_in_memory_indexing(15000000)\n",
    "    indexBuilder.index_merging()\n",
    "\n",
    "    lexicon2 = Lexicon(capacity,\"../Structures/LEXICON/lexicon.bin\",\"../Structures/DOC_INDEX/collection_statistics.bin\")\n",
    "    \n",
    "    found_entry = lexicon2.find_entry(\"random_word_not_present_in_lexicon\")\n",
    "    assert found_entry == None\n",
    "    found_entry = lexicon2.find_entry(\"happiness\")\n",
    "    assert found_entry.term == \"happiness\".ljust(lex_row.MAX_TERM_LENGTH)\n",
    "\n",
    "    assert lexicon2.is_empty()\n",
    "    lex_row = lexicon2.get_entry(\"happiness\")\n",
    "    assert not lexicon2.is_empty()\n",
    "\n",
    "    key = \"happiness\".ljust(lex_row.MAX_TERM_LENGTH)\n",
    "    assert lexicon2.get_terms(key).term == key\n",
    "    assert lexicon2.get_terms(key).term == lex_row.term\n",
    "    assert lexicon2.get_terms(key).dft == lex_row.dft\n",
    "    \n",
    "    lexicon2.close_file()\n",
    "    \n",
    "    if os.path.exists(DIR_LEXICON):\n",
    "        shutil.rmtree(DIR_LEXICON)\n",
    "                \n",
    "    if os.path.exists(DIR_INVERTED_INDEX):\n",
    "        shutil.rmtree(DIR_INVERTED_INDEX)\n",
    "    \n",
    "    if os.path.exists(DIR_DOC_INDEX):\n",
    "        shutil.rmtree(DIR_DOC_INDEX)\n",
    "    \n",
    "    if os.path.exists(DIR_TEMP_FOLDER):\n",
    "        shutil.rmtree(DIR_TEMP_FOLDER)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
