{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c8578f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from C:\\Users\\Davide\\IR\\Progetto\\tests\\Structures\\../..\\structures\\InvertedIndex.ipynb\n",
      "importing Jupyter notebook from C:\\Users\\Davide\\IR\\Progetto\\tests\\Structures\\../..\\structures\\LexiconRow.ipynb\n",
      "importing Jupyter notebook from C:\\Users\\Davide\\IR\\Progetto\\tests\\Structures\\../..\\structures\\DocumentIndex.ipynb\n",
      "importing Jupyter notebook from C:\\Users\\Davide\\IR\\Progetto\\tests\\Structures\\../..\\utilities\\General_Utilities.ipynb\n",
      "importing Jupyter notebook from C:\\Users\\Davide\\IR\\Progetto\\tests\\Structures\\../..\\structures\\DocumentIndexRow.ipynb\n",
      "importing Jupyter notebook from C:\\Users\\Davide\\IR\\Progetto\\tests\\Structures\\../..\\utilities\\Compression.ipynb\n"
     ]
    }
   ],
   "source": [
    "import ipytest\n",
    "import import_ipynb\n",
    "import os\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../')  # Go up two folders to the project root\n",
    "\n",
    "\n",
    "from structures.InvertedIndex import Posting, InvertedIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475bd3bf",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6bb895a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipytest\n",
    "\n",
    "ipytest.autoconfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a567787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                                                           [100%]\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 0.01s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest\n",
    "\n",
    "#Testing Posting methods\n",
    "\n",
    "def test_posting_data_structure():\n",
    "    posting_1=Posting(4,5)\n",
    "    \n",
    "    assert posting_1.doc_id==4\n",
    "    assert posting_1.frequency==5\n",
    "    \n",
    "    posting_2=Posting.from_string(\"1:45\")\n",
    "    assert posting_2.doc_id==1\n",
    "    assert posting_2.frequency==45\n",
    "    \n",
    "    \n",
    "    posting1=Posting.from_string(\"1:2\")\n",
    "    posting2=Posting.from_string(\"56:98\")\n",
    " \n",
    "    assert posting1.doc_id==1\n",
    "    assert posting1.frequency==2\n",
    "    assert posting2.doc_id==56\n",
    "    assert posting2.frequency==98\n",
    "   \n",
    "    \n",
    "def test_posting_write_to_disk():\n",
    "    \n",
    "    posting1=Posting(1,2)\n",
    "    \n",
    "    if os.path.exists(\"prova.bin\"):\n",
    "        os.remove(\"prova.bin\")\n",
    "    \n",
    "    #Write a posting at position 0.\n",
    "    new_free_offset=posting1.write_to_disk(\"prova.bin\",\"type_doc_id\",0)\n",
    "    \n",
    "    #Read it again and check all field are correctly present in binary format.\n",
    "    with open(\"prova.bin\", 'rb') as file:\n",
    "        binaryData=file.read()\n",
    "        assert len(binaryData)==4\n",
    "        assert binaryData[0]==1\n",
    "        assert new_free_offset==4 #integer dimension\n",
    "        \n",
    "    posting2=Posting(57,77)\n",
    "    \n",
    "    #Write a posting at position 4.\n",
    "    new_free_offset=posting2.write_to_disk(\"prova.bin\",\"type_doc_id\",4)\n",
    "    \n",
    "    with open(\"prova.bin\", 'rb') as file:\n",
    "        binaryData=file.read()\n",
    "        assert len(binaryData)==4*2\n",
    "        assert binaryData[0]==1\n",
    "        assert binaryData[4]==57\n",
    "        assert new_free_offset==4*2 #integer dimension\n",
    "        \n",
    "    os.remove(\"prova.bin\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c6cf3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                                                        [100%]\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m5 passed\u001b[0m\u001b[32m in 0.03s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest\n",
    "#Test InvertedIndex Datastructure and methods\n",
    "\n",
    "def test_inverted_index_data_structure_and_main_methods():\n",
    "    ind = InvertedIndex()\n",
    "    ind.add_posting(\"term\", 1, 1)\n",
    "    ind.add_posting(\"term\", 2, 4)\n",
    "    \n",
    "    # Testing existing term\n",
    "    postings = ind.get_postings(\"term\")\n",
    "    assert len(postings) == 2\n",
    "    assert postings[0].doc_id == 1\n",
    "    assert postings[0].frequency == 1\n",
    "    assert postings[1].doc_id == 2\n",
    "    assert postings[1].frequency == 4\n",
    "   \n",
    "    # Testing non-existent term\n",
    "    assert ind.get_postings(\"xyx\") is None\n",
    "    \n",
    "    #Test is_empty and clear_structure and get_structure\n",
    "    assert ind.is_empty() == False\n",
    "    ind.clear_structure()\n",
    "    assert ind.is_empty() ==True\n",
    "    assert ind.get_postings(\"term\") == None\n",
    "    ind.add_posting(\"term\", 57, 4)\n",
    "    ind2=ind.get_structure()\n",
    "    assert ind.get_postings(\"term\")[0].doc_id==ind2[\"term\"][0].doc_id and ind.get_postings(\"term\")[0].frequency==ind2[\"term\"][0].frequency\n",
    "    \n",
    "    #Test vocabulary\n",
    "    ind = InvertedIndex()\n",
    "    ind.add_posting(\"term1\", 1)\n",
    "    ind.add_posting(\"term2\", 1)\n",
    "    ind.add_posting(\"term3\", 2)\n",
    "    ind.add_posting(\"term2\", 3)\n",
    "    assert set(ind.get_terms()) == set([\"term1\", \"term2\", \"term3\"])\n",
    "    \n",
    "    \n",
    "    postingList_1=[Posting(1,2),Posting(2,5),Posting(6,7)]\n",
    "    postingList_2=[Posting(14,3)]\n",
    "    \n",
    "    assert InvertedIndex.merge_posting_lists(postingList_1,postingList_2)==postingList_1+postingList_2\n",
    "    \n",
    "    assert InvertedIndex.compute_max_term_frequency_of_posting_list(postingList_1)==7\n",
    "    assert InvertedIndex.compute_max_term_frequency_of_posting_list(postingList_2)==3\n",
    "    assert InvertedIndex.compute_max_term_frequency_of_posting_list([])==0\n",
    "    \n",
    "    \n",
    "def test_write_to_files_a_posting_list():\n",
    "    \n",
    "    posting_list=[Posting(1,1524),Posting(2,91),Posting(6,101)]\n",
    "    \n",
    "    if os.path.exists(\"doc_ids.bin\"):\n",
    "        os.remove(\"doc_ids.bin\")\n",
    "    \n",
    "    if os.path.exists(\"freq.bin\"):\n",
    "        os.remove(\"freq.bin\")\n",
    "    \n",
    "    file_doc_ids=open(\"doc_ids.bin\", 'ab') \n",
    "    file_freq=open(\"freq.bin\", 'ab')\n",
    "    \n",
    "    new_doc_ids_offset,new_freq_offset=InvertedIndex.write_to_files_a_posting_list(posting_list,False,file_doc_ids,file_freq,0,0)\n",
    "    \n",
    "    file_doc_ids.close()  \n",
    "    file_freq.close()\n",
    "    \n",
    "    file_doc_ids_read=open(\"doc_ids.bin\", 'rb') \n",
    "    file_freq_read=open(\"freq.bin\", 'rb')\n",
    "    \n",
    "    doc_id_contents=file_doc_ids_read.read()\n",
    "    freq_contents=file_freq_read.read()\n",
    "    \n",
    "    file_doc_ids_read.close()\n",
    "    file_freq_read.close()\n",
    "    \n",
    "    assert new_doc_ids_offset==4*len(posting_list)\n",
    "    assert new_freq_offset==4*len(posting_list)\n",
    "    \n",
    "    assert doc_id_contents[0]==0\n",
    "    assert doc_id_contents[1]==0\n",
    "    assert doc_id_contents[2]==0\n",
    "    assert doc_id_contents[3]==1\n",
    "    \n",
    "    assert doc_id_contents[4]==0\n",
    "    assert doc_id_contents[5]==0\n",
    "    assert doc_id_contents[6]==0\n",
    "    assert doc_id_contents[7]==2\n",
    "    \n",
    "    assert doc_id_contents[8]==0\n",
    "    assert doc_id_contents[9]==0\n",
    "    assert doc_id_contents[10]==0\n",
    "    assert doc_id_contents[11]==6\n",
    "    \n",
    "    \n",
    "    assert freq_contents[0]==0\n",
    "    assert freq_contents[1]==0\n",
    "    assert freq_contents[2]==5\n",
    "    assert freq_contents[3]==244\n",
    "    \n",
    "    assert freq_contents[4]==0\n",
    "    assert freq_contents[5]==0\n",
    "    assert freq_contents[6]==0\n",
    "    assert freq_contents[7]==91\n",
    "    \n",
    "    assert freq_contents[8]==0\n",
    "    assert freq_contents[9]==0\n",
    "    assert freq_contents[10]==0\n",
    "    assert freq_contents[11]==101\n",
    "    \n",
    "    #Adding new element and save it on disk.\n",
    "    \n",
    "    posting_list_new=[Posting(14,3)]\n",
    "    \n",
    "    \n",
    "    file_doc_ids=open(\"doc_ids.bin\", 'ab') \n",
    "    file_freq=open(\"freq.bin\", 'ab')\n",
    "    \n",
    "    new_doc_ids_offset,new_freq_offset=InvertedIndex.write_to_files_a_posting_list(posting_list_new,False,file_doc_ids,file_freq,new_doc_ids_offset,new_freq_offset)\n",
    "    \n",
    "    file_doc_ids.close()  \n",
    "    file_freq.close()\n",
    "    \n",
    "    file_doc_ids_read=open(\"doc_ids.bin\", 'rb') \n",
    "    file_freq_read=open(\"freq.bin\", 'rb')\n",
    "    \n",
    "    doc_id_contents=file_doc_ids_read.read()\n",
    "    freq_contents=file_freq_read.read()\n",
    "    \n",
    "    file_doc_ids_read.close()\n",
    "    file_freq_read.close()\n",
    "    \n",
    "    assert new_doc_ids_offset==4*len(posting_list)+4*len(posting_list_new)\n",
    "    assert new_freq_offset==4*len(posting_list)+4*len(posting_list_new)\n",
    "    \n",
    "    #The same test as before, nothing should be changed.\n",
    "    \n",
    "    assert doc_id_contents[0]==0\n",
    "    assert doc_id_contents[1]==0\n",
    "    assert doc_id_contents[2]==0\n",
    "    assert doc_id_contents[3]==1\n",
    "    \n",
    "    assert doc_id_contents[4]==0\n",
    "    assert doc_id_contents[5]==0\n",
    "    assert doc_id_contents[6]==0\n",
    "    assert doc_id_contents[7]==2\n",
    "    \n",
    "    assert doc_id_contents[8]==0\n",
    "    assert doc_id_contents[9]==0\n",
    "    assert doc_id_contents[10]==0\n",
    "    assert doc_id_contents[11]==6\n",
    "    \n",
    "    \n",
    "    assert freq_contents[0]==0\n",
    "    assert freq_contents[1]==0\n",
    "    assert freq_contents[2]==5\n",
    "    assert freq_contents[3]==244\n",
    "    \n",
    "    assert freq_contents[4]==0\n",
    "    assert freq_contents[5]==0\n",
    "    assert freq_contents[6]==0\n",
    "    assert freq_contents[7]==91\n",
    "    \n",
    "    assert freq_contents[8]==0\n",
    "    assert freq_contents[9]==0\n",
    "    assert freq_contents[10]==0\n",
    "    assert freq_contents[11]==101\n",
    "    \n",
    "    #Testing new element already added.\n",
    "    \n",
    "    assert doc_id_contents[12]==0\n",
    "    assert doc_id_contents[13]==0\n",
    "    assert doc_id_contents[14]==0\n",
    "    assert doc_id_contents[15]==14\n",
    "    \n",
    "    assert freq_contents[12]==0\n",
    "    assert freq_contents[13]==0\n",
    "    assert freq_contents[14]==0\n",
    "    assert freq_contents[15]==3\n",
    "    \n",
    "    os.remove(\"doc_ids.bin\")\n",
    "    os.remove(\"freq.bin\")\n",
    "    \n",
    "    \n",
    "    #Testing the same thing but with compression true\n",
    "    \n",
    "    posting_list=[Posting(1,3),Posting(2,5),Posting(6,7)]\n",
    "    \n",
    "    file_doc_ids=open(\"doc_ids.bin\", 'ab') \n",
    "    file_freq=open(\"freq.bin\", 'ab')\n",
    "    \n",
    "    new_doc_ids_offset,new_freq_offset=InvertedIndex.write_to_files_a_posting_list(posting_list,True,file_doc_ids,file_freq,0,0)\n",
    "    \n",
    "    file_doc_ids.close()  \n",
    "    file_freq.close()\n",
    "    \n",
    "    file_doc_ids_read=open(\"doc_ids.bin\", 'rb') \n",
    "    file_freq_read=open(\"freq.bin\", 'rb')\n",
    "    \n",
    "    doc_id_contents=file_doc_ids_read.read()\n",
    "    freq_contents=file_freq_read.read()\n",
    "    \n",
    "    file_doc_ids_read.close()\n",
    "    file_freq_read.close()\n",
    "    \n",
    "    #Remember for doc_id used d-gap compression\n",
    "    assert new_doc_ids_offset==3\n",
    "    assert new_freq_offset==2\n",
    "    \n",
    "    assert len(doc_id_contents)==3\n",
    "    assert doc_id_contents[0]==1\n",
    "    assert doc_id_contents[1]==1\n",
    "    assert doc_id_contents[2]==4\n",
    "    \n",
    "    #Remember for freq used unary compression\n",
    "    assert freq_contents[0]==222\n",
    "    assert freq_contents[1]==252\n",
    "   \n",
    "    new_posting_list_new=[Posting(14,1)]\n",
    "    \n",
    "    file_doc_ids=open(\"doc_ids.bin\", 'ab') \n",
    "    file_freq=open(\"freq.bin\", 'ab')\n",
    "    \n",
    "    new_doc_ids_offset,new_freq_offset=InvertedIndex.write_to_files_a_posting_list(new_posting_list_new,True,file_doc_ids,file_freq,new_doc_ids_offset,new_freq_offset)\n",
    "    \n",
    "    file_doc_ids.close()  \n",
    "    file_freq.close()\n",
    "    \n",
    "    file_doc_ids_read=open(\"doc_ids.bin\", 'rb') \n",
    "    file_freq_read=open(\"freq.bin\", 'rb')\n",
    "    \n",
    "    doc_id_contents=file_doc_ids_read.read()\n",
    "    freq_contents=file_freq_read.read()\n",
    "    \n",
    "    file_doc_ids_read.close()\n",
    "    file_freq_read.close()\n",
    "    \n",
    "    #Remember for doc_id used d-gap compression\n",
    "    assert new_doc_ids_offset==4\n",
    "    assert new_freq_offset==3\n",
    "    \n",
    "    assert len(doc_id_contents)==4\n",
    "    assert doc_id_contents[0]==1\n",
    "    assert doc_id_contents[1]==1\n",
    "    assert doc_id_contents[2]==4\n",
    "    assert doc_id_contents[3]==1\n",
    "    \n",
    "    #Remember for freq used unary compression\n",
    "    assert freq_contents[0]==222\n",
    "    assert freq_contents[1]==252\n",
    "    assert freq_contents[2]==0\n",
    "    \n",
    "    os.remove(\"doc_ids.bin\")\n",
    "    os.remove(\"freq.bin\")\n",
    "    \n",
    "       \n",
    "def test_read_from_files_a_posting_list():\n",
    "   \n",
    "    if os.path.exists(\"doc_ids.bin\"):\n",
    "        os.remove(\"doc_ids.bin\")\n",
    "    \n",
    "    if os.path.exists(\"freq.bin\"):\n",
    "        os.remove(\"freq.bin\")\n",
    "    \n",
    "    posting_list=[Posting(1,3),Posting(2,5),Posting(6,7)]\n",
    "    \n",
    "    file_doc_ids=open(\"doc_ids.bin\", 'ab') \n",
    "    file_freq=open(\"freq.bin\", 'ab')\n",
    "    \n",
    "    new_doc_ids_offset,new_freq_offset=InvertedIndex.write_to_files_a_posting_list(posting_list,False,file_doc_ids,file_freq,0,0)\n",
    "    \n",
    "    file_doc_ids.close()  \n",
    "    file_freq.close()\n",
    "    \n",
    "    file_doc_ids_read=open(\"doc_ids.bin\", 'rb') \n",
    "    file_freq_read=open(\"freq.bin\", 'rb')\n",
    "    \n",
    "    loaded_posting_list,new_doc_offset,new_freq_offset=InvertedIndex.read_from_files_a_posting_list(file_doc_ids_read,file_freq_read,False,0,0,3)\n",
    "    \n",
    "    file_doc_ids_read.close()\n",
    "    file_freq_read.close()\n",
    "    \n",
    "    assert len(loaded_posting_list)==len(posting_list)\n",
    "    \n",
    "    assert new_doc_offset==4*len(loaded_posting_list)\n",
    "    assert new_freq_offset==4*len(loaded_posting_list)\n",
    "    assert loaded_posting_list[0].doc_id==posting_list[0].doc_id\n",
    "    assert loaded_posting_list[0].frequency==posting_list[0].frequency\n",
    "    assert loaded_posting_list[1].doc_id==posting_list[1].doc_id\n",
    "    assert loaded_posting_list[1].frequency==posting_list[1].frequency\n",
    "    assert loaded_posting_list[2].doc_id==posting_list[2].doc_id\n",
    "    assert loaded_posting_list[2].frequency==posting_list[2].frequency\n",
    "    \n",
    "    \n",
    "    #Read just a subset of posting from the second pos to third.\n",
    "    \n",
    "    file_doc_ids_read=open(\"doc_ids.bin\", 'rb') \n",
    "    file_freq_read=open(\"freq.bin\", 'rb')\n",
    "    \n",
    "    loaded_posting_list,new_doc_offset,new_freq_offset=InvertedIndex.read_from_files_a_posting_list(file_doc_ids_read,file_freq_read,False,4,4,2)\n",
    "    \n",
    "    file_doc_ids_read.close()\n",
    "    file_freq_read.close()\n",
    "    \n",
    "    \n",
    "    assert len(loaded_posting_list)==len(posting_list)-1\n",
    "    \n",
    "    assert loaded_posting_list[0].doc_id==posting_list[1].doc_id\n",
    "    assert loaded_posting_list[0].frequency==posting_list[1].frequency\n",
    "    assert loaded_posting_list[1].doc_id==posting_list[2].doc_id\n",
    "    assert loaded_posting_list[1].frequency==posting_list[2].frequency\n",
    "\n",
    "    os.remove(\"doc_ids.bin\")\n",
    "    os.remove(\"freq.bin\")\n",
    "    \n",
    "    #Do the same but considering compression\n",
    "    \n",
    "    posting_list=[Posting(1,3),Posting(2,5),Posting(6,7)]\n",
    "    \n",
    "    file_doc_ids=open(\"doc_ids.bin\", 'ab') \n",
    "    file_freq=open(\"freq.bin\", 'ab')\n",
    "    \n",
    "    new_doc_ids_offset,new_freq_offset=InvertedIndex.write_to_files_a_posting_list(posting_list,True,file_doc_ids,file_freq,0,0)\n",
    "    \n",
    "    file_doc_ids.close()  \n",
    "    file_freq.close()\n",
    "    \n",
    "    file_doc_ids_read=open(\"doc_ids.bin\", 'rb') \n",
    "    file_freq_read=open(\"freq.bin\", 'rb')\n",
    "    \n",
    "    #This information should arrive from block descriptor\n",
    "    doc_id_size=new_doc_ids_offset\n",
    "    freq_size=new_freq_offset\n",
    "    min_doc_id=1\n",
    "    \n",
    "    loaded_posting_list,new_doc_offset,new_freq_offset=InvertedIndex.read_from_files_a_posting_list(file_doc_ids_read,file_freq_read,True,0,0,3,doc_id_size,freq_size,min_doc_id)\n",
    "    \n",
    "    file_doc_ids_read.close()\n",
    "    file_freq_read.close()\n",
    "    \n",
    "    assert len(loaded_posting_list)==len(posting_list)\n",
    "    \n",
    "    #Remember for doc_id used d-gap compression\n",
    "    assert new_doc_offset==3\n",
    "    #Remember for freq used unary compression\n",
    "    assert new_freq_offset==2\n",
    "    \n",
    "    assert loaded_posting_list[0].doc_id==posting_list[0].doc_id\n",
    "    assert loaded_posting_list[0].frequency==posting_list[0].frequency\n",
    "    assert loaded_posting_list[1].doc_id==posting_list[1].doc_id\n",
    "    assert loaded_posting_list[1].frequency==posting_list[1].frequency\n",
    "    assert loaded_posting_list[2].doc_id==posting_list[2].doc_id\n",
    "    assert loaded_posting_list[2].frequency==posting_list[2].frequency\n",
    "\n",
    "    os.remove(\"doc_ids.bin\")\n",
    "    os.remove(\"freq.bin\")\n",
    "    \n",
    "    \n",
    "    \n",
    "def test_write_to_block_all_index_in_memory():\n",
    "    \n",
    "    ind=InvertedIndex()\n",
    "    ind.add_posting(\"ciao\", 1, 5)\n",
    "    ind.add_posting(\"ciao\", 2, 3)\n",
    "    \n",
    "    ind.add_posting(\"dado\", 1, 8)\n",
    "    ind.add_posting(\"dado\", 3, 1)\n",
    "    \n",
    "    ind.add_posting(\"penna\", 4, 1)\n",
    "    ind.add_posting(\"penna\", 5, 3)\n",
    "    ind.add_posting(\"penna\", 6, 1)\n",
    "    \n",
    "\n",
    "    ind.write_to_block_all_index_in_memory(\"lexicon.bin\",\"doc_ids.bin\",\"freq.bin\")\n",
    "    \n",
    "    assert os.path.exists(\"lexicon.bin\")==True\n",
    "    assert os.path.exists(\"doc_ids.bin\")==True\n",
    "    assert os.path.exists(\"freq.bin\")==True\n",
    "    \n",
    "    file_lexicon_read=open(\"lexicon.bin\", 'rb') \n",
    "    file_doc_ids_read=open(\"doc_ids.bin\", 'rb') \n",
    "    file_freq_read=open(\"freq.bin\", 'rb')\n",
    "    \n",
    "    \n",
    "    byteLexicon=file_lexicon_read.read()\n",
    "    byteDoc_ids=file_doc_ids_read.read()\n",
    "    byteFreq=file_freq_read.read()\n",
    "    \n",
    "\n",
    "    file_lexicon_read.close()\n",
    "    file_doc_ids_read.close()\n",
    "    file_freq_read.close()\n",
    "    \n",
    "    #Just to check if lexicon file is not empty and contains the three terms.\n",
    "    \n",
    "    #Correct lexicon term saved.\n",
    "    assert str(byteLexicon[0:4])==\"b'ciao'\"\n",
    "    assert str(byteLexicon[84:88])==\"b'dado'\"\n",
    "    assert str(byteLexicon[168:173])==\"b'penna'\"\n",
    "    \n",
    "    #Tot postings.\n",
    "    assert byteLexicon[32]==2\n",
    "    assert byteLexicon[116]==2\n",
    "    assert byteLexicon[200]==3\n",
    "    \n",
    "    #Other checks are done in LexiconRow File\n",
    "    \n",
    "    assert byteDoc_ids[0]==0\n",
    "    assert byteDoc_ids[1]==0\n",
    "    assert byteDoc_ids[2]==0\n",
    "    assert byteDoc_ids[3]==1\n",
    "    \n",
    "    assert byteDoc_ids[4]==0\n",
    "    assert byteDoc_ids[5]==0\n",
    "    assert byteDoc_ids[6]==0\n",
    "    assert byteDoc_ids[7]==2\n",
    "    \n",
    "    assert byteDoc_ids[8]==0\n",
    "    assert byteDoc_ids[9]==0\n",
    "    assert byteDoc_ids[10]==0\n",
    "    assert byteDoc_ids[11]==1\n",
    "    \n",
    "    assert byteDoc_ids[12]==0\n",
    "    assert byteDoc_ids[13]==0\n",
    "    assert byteDoc_ids[14]==0\n",
    "    assert byteDoc_ids[15]==3\n",
    "    \n",
    "    assert byteDoc_ids[19]==4\n",
    "    assert byteDoc_ids[23]==5\n",
    "    assert byteDoc_ids[27]==6\n",
    "    \n",
    "    assert byteFreq[0]==0\n",
    "    assert byteFreq[1]==0\n",
    "    assert byteFreq[2]==0\n",
    "    assert byteFreq[3]==5\n",
    "    \n",
    "    assert byteFreq[4]==0\n",
    "    assert byteFreq[5]==0\n",
    "    assert byteFreq[6]==0\n",
    "    assert byteFreq[7]==3\n",
    "    \n",
    "    assert byteFreq[8]==0\n",
    "    assert byteFreq[9]==0\n",
    "    assert byteFreq[10]==0\n",
    "    assert byteFreq[11]==8\n",
    "    \n",
    "    assert byteFreq[12]==0\n",
    "    assert byteFreq[13]==0\n",
    "    assert byteFreq[14]==0\n",
    "    assert byteFreq[15]==1\n",
    "    \n",
    "    assert byteFreq[19]==1\n",
    "    assert byteFreq[23]==3\n",
    "    assert byteFreq[27]==1\n",
    "    \n",
    "    if os.path.exists(\"lexicon.bin\"):\n",
    "        os.remove(\"lexicon.bin\")\n",
    "           \n",
    "    if os.path.exists(\"doc_ids.bin\"):\n",
    "        os.remove(\"doc_ids.bin\")\n",
    "        \n",
    "    if os.path.exists(\"freq.bin\"):\n",
    "        os.remove(\"freq.bin\")    \n",
    "    \n",
    "    \n",
    "    \n",
    "def test_read_from_block_all_index_in_memory():\n",
    "    \n",
    "    ind=InvertedIndex()\n",
    "    ind.add_posting(\"ciao\", 1, 5)\n",
    "    ind.add_posting(\"ciao\", 2, 3)\n",
    "    \n",
    "    ind.add_posting(\"dado\", 1, 8)\n",
    "    ind.add_posting(\"dado\", 3, 1)\n",
    "    \n",
    "    ind.add_posting(\"penna\", 4, 1)\n",
    "    ind.add_posting(\"penna\", 5, 3)\n",
    "    ind.add_posting(\"penna\", 6, 1)\n",
    "    \n",
    "\n",
    "    ind.write_to_block_all_index_in_memory(\"lexicon.bin\",\"doc_ids.bin\",\"freq.bin\")\n",
    "    \n",
    "    \n",
    "    ind2=InvertedIndex()\n",
    "    \n",
    "    ind2.read_from_block_all_index_in_memory(\"lexicon.bin\",\"doc_ids.bin\",\"freq.bin\")\n",
    "    \n",
    "    posting_ciao=ind2.get_postings(\"ciao\".ljust(30))\n",
    "    posting_dado=ind2.get_postings(\"dado\".ljust(30))\n",
    "    posting_penna=ind2.get_postings(\"penna\".ljust(30))\n",
    "    \n",
    "    posting_nulla=ind2.get_postings(\"nulla\".ljust(30))\n",
    "    \n",
    "    assert len(posting_ciao)==2\n",
    "    assert len(posting_dado)==2\n",
    "    assert len(posting_penna)==3\n",
    "    assert posting_nulla==None\n",
    "    \n",
    "    assert posting_ciao[0].doc_id==1\n",
    "    assert posting_ciao[1].doc_id==2\n",
    "    \n",
    "    assert posting_dado[0].doc_id==1\n",
    "    assert posting_dado[1].doc_id==3\n",
    "    \n",
    "    assert posting_penna[0].doc_id==4\n",
    "    assert posting_penna[1].doc_id==5\n",
    "    assert posting_penna[2].doc_id==6\n",
    "    \n",
    "    assert posting_ciao[0].frequency==5\n",
    "    assert posting_ciao[1].frequency==3\n",
    "    \n",
    "    assert posting_dado[0].frequency==8\n",
    "    assert posting_dado[1].frequency==1\n",
    "    \n",
    "    assert posting_penna[0].frequency==1\n",
    "    assert posting_penna[1].frequency==3\n",
    "    assert posting_penna[2].frequency==1\n",
    "    \n",
    "    \n",
    "    if os.path.exists(\"lexicon.bin\"):\n",
    "        os.remove(\"lexicon.bin\")\n",
    "           \n",
    "    if os.path.exists(\"doc_ids.bin\"):\n",
    "        os.remove(\"doc_ids.bin\")\n",
    "        \n",
    "    if os.path.exists(\"freq.bin\"):\n",
    "        os.remove(\"freq.bin\")    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
