{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "066c036c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../')  # Go up two folders to the project root\n",
    "\n",
    "from structures.InvertedIndex import Posting, InvertedIndex\n",
    "from building_data_structures.IndexBuilder import IndexBuilder \n",
    "from structures.DocumentIndex import DocumentIndex\n",
    "from pre_processing.Decompress_collection import Collection_Reader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dd521b",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b65ba037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipytest\n",
    "\n",
    "ipytest.autoconfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d91c7ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Costants\n",
    "\n",
    "DIR_TEMP_FOLDER=\"TEMP\"\n",
    "DIR_TEMP_DOC_ID=\"DOC_ID_TEMP\"\n",
    "DIR_TEMP_FREQ=\"FREQ_TEMP\"\n",
    "DIR_TEMP_LEXICON=\"LEXICON_TEMP\"\n",
    "\n",
    "DIR_LEXICON=\"LEXICON\"\n",
    "DIR_DOC_INDEX=\"DOC_INDEX\"\n",
    "DIR_INVERTED_INDEX=\"INV_INDEX\"\n",
    "\n",
    "PATH_FINAL_LEXICON=\"lexicon.bin\"\n",
    "PATH_FINAL_DOC_IDS=\"doc_ids.bin\"\n",
    "PATH_FINAL_FREQ=\"freq.bin\"\n",
    "PATH_FINAL_BLOCK_DESCRIPTOR=\"block_descriptors.bin\"\n",
    "PATH_FINAL_DOCUMENT_INDEX=\"document_index.bin\"\n",
    "\n",
    "\n",
    "PATH_COLLECTION_STATISTICS=\"collection_statistics.bin\"\n",
    "PATH_COLLECTION_STATISTICS_DEBUG=\"collection_statistics.txt\"\n",
    "\n",
    "PATH_FINAL_INVERTED_INDEX_DEBUG=\"inverted_index.txt\"\n",
    "PATH_FINAL_LEXICON_DEBUG=\"lexicon.txt\"\n",
    "PATH_FINAL_DOCUMENT_INDEX_DEBUG=\"document_index.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9bfbe2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                                                           [100%]\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 0.01s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest\n",
    "\n",
    "#Test InvertedIndex and Posting datastructures\n",
    "\n",
    "def test_inverted_index_data_structure_and_methods():\n",
    "    ind = InvertedIndex()\n",
    "    ind.add_posting(\"term\", 1, 1)\n",
    "    ind.add_posting(\"term\", 2, 4)\n",
    "    \n",
    "    # Testing existing term\n",
    "    postings = ind.get_postings(\"term\")\n",
    "    assert len(postings) == 2\n",
    "    assert postings[0].doc_id == 1\n",
    "    assert postings[0].frequency == 1\n",
    "    assert postings[1].doc_id == 2\n",
    "    assert postings[1].frequency == 4\n",
    "   \n",
    "    # Testing non-existent term\n",
    "    assert ind.get_postings(\"xyx\") is None\n",
    "    \n",
    "    #Test is_empty and clear_structure and get_structure\n",
    "    assert ind.is_empty() == False\n",
    "    ind.clear_structure()\n",
    "    assert ind.is_empty() ==True\n",
    "    assert ind.get_postings(\"term\") == None\n",
    "    ind.add_posting(\"term\", 57, 4)\n",
    "    ind2=ind.get_structure()\n",
    "    assert ind.get_postings(\"term\")[0].doc_id==ind2[\"term\"][0].doc_id and ind.get_postings(\"term\")[0].frequency==ind2[\"term\"][0].frequency\n",
    "    \n",
    "    #Test vocabulary\n",
    "    ind = InvertedIndex()\n",
    "    ind.add_posting(\"term1\", 1)\n",
    "    ind.add_posting(\"term2\", 1)\n",
    "    ind.add_posting(\"term3\", 2)\n",
    "    ind.add_posting(\"term2\", 3)\n",
    "    assert set(ind.get_terms()) == set([\"term1\", \"term2\", \"term3\"])\n",
    "    \n",
    "def test_posting_data_structure():\n",
    "    posting_1=Posting(4,5)\n",
    "    \n",
    "    assert posting_1.doc_id==4\n",
    "    assert posting_1.frequency==5\n",
    "    \n",
    "    posting_2=Posting.from_string(\"1:45\")\n",
    "    assert posting_2.doc_id==1\n",
    "    assert posting_2.frequency==45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a11780bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.01s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest\n",
    "\n",
    "#In this part I'm gonna test the local structure for saving an entire inverted index in main memory.\n",
    "#If this structure and its method is ok, then I can use it to simplfy further testing for complex documents.\n",
    "\n",
    "test_documents=[\n",
    "    \"0\\t this is a random sentence without punctuation\",\n",
    "    \"1\\t python is a versatile programming language\",\n",
    "    \"2\\t the quick brown fox jumps over the lazy dog\",\n",
    "    \"3\\t coding is a creative and logical process\",\n",
    "    \"4\\t sunsets are a beautiful sight to behold\",\n",
    "    \"5\\t coffee is a popular beverage around the world\",\n",
    "    \"6\\t music has the power to evoke emotions\",\n",
    "    \"7\\t books transport readers to different worlds\",\n",
    "    \"8\\t kindness and compassion make the world better\",\n",
    "    \"9\\t the moonlight reflects on the calm lake in the night the vision is awesome\",\n",
    "    \"10\\t nature provides solace and tranquility\",\n",
    "    \"11\\t imagination knows no boundaries\",\n",
    "    \"12\\t friendship is a treasure worth cherishing\",\n",
    "    \"13\\t happiness is found in simple moments\",\n",
    "    \"14\\t laughter is contagious and brings joy is better for all\"\n",
    "]\n",
    "\n",
    "\n",
    "def test_index_building():\n",
    "\n",
    "    #Test buildInMemoryIndex\n",
    "    \n",
    "    indexBuilder=IndexBuilder(False,False,Collection_Reader(\"\",-1,-1,False,False,test_documents))\n",
    "    index=indexBuilder.build_in_memory_index(test_documents)\n",
    "    \n",
    "    assert len(index.get_postings(\"is\"))==8 \n",
    "    assert index.get_postings(\"is\")[2].doc_id==3 and index.get_postings(\"is\")[2].frequency==1\n",
    "    assert index.get_postings(\"is\")[7].doc_id==14 and index.get_postings(\"is\")[7].frequency==2\n",
    "    \n",
    "    assert len(index.get_postings(\"python\"))==1 \n",
    "    assert index.get_postings(\"python\")[0].doc_id==1 and index.get_postings(\"python\")[0].frequency==1\n",
    "    \n",
    "    assert len(index.get_postings(\"the\"))==5 \n",
    "    assert index.get_postings(\"the\")[4].doc_id==9 and index.get_postings(\"the\")[4].frequency==4\n",
    "    \n",
    "    assert len(index.get_postings(\"friendship\"))==1 \n",
    "    assert index.get_postings(\"friendship\")[0].doc_id==12\n",
    "    assert index.get_postings(\"friendship\")[0].frequency==1\n",
    "    \n",
    "    if os.path.exists(DIR_LEXICON):\n",
    "        shutil.rmtree(DIR_LEXICON)\n",
    "                \n",
    "    if os.path.exists(DIR_INVERTED_INDEX):\n",
    "        shutil.rmtree(DIR_INVERTED_INDEX)\n",
    "    \n",
    "    if os.path.exists(DIR_DOC_INDEX):\n",
    "        shutil.rmtree(DIR_DOC_INDEX)\n",
    "    \n",
    "    if os.path.exists(DIR_TEMP_FOLDER):\n",
    "        shutil.rmtree(DIR_TEMP_FOLDER)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "764b647b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.04s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest\n",
    "\n",
    "\n",
    "#The goal of this test is not to test if text_processing or compression is done, but just to consider\n",
    "# if all the necessary data structure are created correctly and finally that the result is consistent with\n",
    "# the method created above.\n",
    "\n",
    "test_documents=[\n",
    "    \"0\\t this is a random sentence without punctuation\",\n",
    "    \"1\\t python is a versatile programming language\",\n",
    "    \"2\\t the quick brown fox jumps over the lazy dog\",\n",
    "    \"3\\t coding is a creative and logical process\",\n",
    "    \"4\\t sunsets are a beautiful sight to behold\",\n",
    "    \"5\\t coffee is a popular beverage around the world\",\n",
    "    \"6\\t music has the power to evoke emotions\",\n",
    "    \"7\\t books transport readers to different worlds\",\n",
    "    \"8\\t kindness and compassion make the world better\",\n",
    "    \"9\\t the moonlight reflects on the calm lake in the night the vision is awesome\",\n",
    "    \"10\\t nature provides solace and tranquility\",\n",
    "    \"11\\t imagination knows no boundaries\",\n",
    "    \"12\\t friendship is a treasure worth cherishing\",\n",
    "    \"13\\t happiness is found in simple moments\",\n",
    "    \"14\\t laughter is contagious and brings joy is better for all\"\n",
    "]\n",
    "\n",
    "def test_correctness_of_spimi_plus_merging_with_multiple_block_size_creation_of_files(): \n",
    "     \n",
    "        indexBuilder=IndexBuilder(True,False,Collection_Reader(\"\",-1,-1,False,False,test_documents))\n",
    "        indexBuilder.single_pass_in_memory_indexing(500)\n",
    "        indexBuilder.index_merging()\n",
    "    \n",
    "        #Check if directories exists and are full of files\n",
    "        \n",
    "        if os.path.exists(DIR_TEMP_FOLDER):\n",
    "            assert 1==1\n",
    "        else:\n",
    "            assert 1==-1\n",
    "            \n",
    "        if os.path.exists(DIR_DOC_INDEX):\n",
    "            assert 1==1\n",
    "        else:\n",
    "            assert 1==2\n",
    "        \n",
    "        if os.path.exists(DIR_INVERTED_INDEX):\n",
    "            assert 1==1\n",
    "        else:\n",
    "            assert 1==3\n",
    "        \n",
    "        if os.path.exists(DIR_LEXICON):\n",
    "            assert 1==1\n",
    "        else:\n",
    "            assert 1==4\n",
    "            \n",
    "        directory_list=[DIR_TEMP_DOC_ID,DIR_TEMP_FREQ,DIR_TEMP_LEXICON]\n",
    "        \n",
    "        #Check if all the files inside TEMP are present and not empty: so this means that SPIMI has done its job correctly.\n",
    "        for directory_name in directory_list:\n",
    "            directory_path = os.path.join(DIR_TEMP_FOLDER, directory_name)\n",
    "\n",
    "            if os.path.exists(directory_path) and os.path.isdir(directory_path):\n",
    "                print(f\"Checking files in directory: {directory_name}\")\n",
    "\n",
    "                # List all files in the directory\n",
    "                files = [f for f in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, f))]\n",
    "\n",
    "                if not files:\n",
    "                    print(f\"No files found in directory: {directory_name}\")\n",
    "                    assert 1==5\n",
    "                else:\n",
    "                    for filename in files:\n",
    "                        file_path = os.path.join(directory_path, filename)\n",
    "                        if os.path.getsize(file_path) > 0:\n",
    "                            print(f\"{filename} in {directory_name} is not empty.\")\n",
    "                            assert 1==1\n",
    "                        else:\n",
    "                            print(f\"{filename} in {directory_name} is either empty or doesn't exist.\")\n",
    "                            assert 1==6\n",
    "            else:\n",
    "                print(f\"Directory {directory_name} either doesn't exist or is not a directory.\")\n",
    "                assert 1==7\n",
    "        \n",
    "        #Test if debug is printed and considered.\n",
    "        i=0\n",
    "        for file in os.listdir(directory_path):\n",
    "            if (file not in directory_list):\n",
    "                i+=1\n",
    "        assert i!=0\n",
    "        \n",
    "        #Check if all the files inside DOC_INDEX are present and not empty: so this means that SPIMI has done its job correctly.\n",
    "        file_list=[PATH_COLLECTION_STATISTICS,PATH_COLLECTION_STATISTICS_DEBUG,PATH_FINAL_DOCUMENT_INDEX,PATH_FINAL_DOCUMENT_INDEX_DEBUG]\n",
    "        \n",
    "        i=0\n",
    "        for file_name in file_list:\n",
    "            nuovo_file=os.path.join(DIR_DOC_INDEX,file_name)\n",
    "            if os.path.exists(nuovo_file) and os.path.getsize(nuovo_file) > 0:\n",
    "                i+=1\n",
    "        assert i==len(file_list)\n",
    "        \n",
    "        #Check if all the files inside INV_INDEX are present and not empty: so this means that MERGER has done its job correctly.\n",
    "        \n",
    "        file_list=[PATH_FINAL_DOC_IDS,PATH_FINAL_FREQ,PATH_FINAL_BLOCK_DESCRIPTOR,PATH_FINAL_INVERTED_INDEX_DEBUG]\n",
    "        \n",
    "        i=0\n",
    "        for file_name in file_list:\n",
    "            nuovo_file=os.path.join(DIR_INVERTED_INDEX,file_name)\n",
    "            if os.path.exists(nuovo_file) and os.path.getsize(nuovo_file) > 0:\n",
    "                i+=1\n",
    "        assert i==len(file_list)        \n",
    "          \n",
    "        #Check if all the files inside LEXICON are present and not empty: so this means that MERGER has done its job correctly.\n",
    "        \n",
    "        file_list=[PATH_FINAL_LEXICON,PATH_FINAL_LEXICON_DEBUG]\n",
    "        \n",
    "        i=0\n",
    "        for file_name in file_list:\n",
    "            nuovo_file=os.path.join(DIR_LEXICON,file_name)\n",
    "            if os.path.exists(nuovo_file) and os.path.getsize(nuovo_file) > 0:\n",
    "                i+=1\n",
    "        \n",
    "        assert i==len(file_list) \n",
    "        \n",
    "        if os.path.exists(DIR_LEXICON):\n",
    "            shutil.rmtree(DIR_LEXICON)\n",
    "\n",
    "        if os.path.exists(DIR_INVERTED_INDEX):\n",
    "            shutil.rmtree(DIR_INVERTED_INDEX)\n",
    "\n",
    "        if os.path.exists(DIR_DOC_INDEX):\n",
    "            shutil.rmtree(DIR_DOC_INDEX)\n",
    "\n",
    "        if os.path.exists(DIR_TEMP_FOLDER):\n",
    "            shutil.rmtree(DIR_TEMP_FOLDER)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdf550ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.04s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest\n",
    "test_documents=[\n",
    "    \"0\\t this is a random sentence without punctuation\",\n",
    "    \"1\\t python is a versatile programming language\",\n",
    "    \"2\\t the quick brown fox jumps over the lazy dog\",\n",
    "    \"3\\t coding is a creative and logical process\",\n",
    "    \"4\\t sunsets are a beautiful sight to behold\",\n",
    "    \"5\\t coffee is a popular beverage around the world\",\n",
    "    \"6\\t music has the power to evoke emotions\",\n",
    "    \"7\\t books transport readers to different worlds\",\n",
    "    \"8\\t kindness and compassion make the world better\",\n",
    "    \"9\\t the moonlight reflects on the calm lake in the night the vision is awesome\",\n",
    "    \"10\\t nature provides solace and tranquility\",\n",
    "    \"11\\t imagination knows no boundaries\",\n",
    "    \"12\\t friendship is a treasure worth cherishing\",\n",
    "    \"13\\t happiness is found in simple moments\",\n",
    "    \"14\\t laughter is contagious and brings joy is better for all\"\n",
    "]\n",
    "#Here using the previous data structure to check if using spimi + merging it obtains the same result.\n",
    "def test_correctness_of_spimi_plus_merging_with_multiple_block_size_content_of_index():\n",
    "    \n",
    "    indexBuilder=IndexBuilder(True,False,Collection_Reader(\"\",-1,-1,False,False,test_documents))\n",
    "    indexBuilder.single_pass_in_memory_indexing(500)\n",
    "    indexBuilder.index_merging()\n",
    "    \n",
    "    \n",
    "    ind_read_from_disk=InvertedIndex()\n",
    "    \n",
    "    i=0\n",
    "    with open(DIR_INVERTED_INDEX+\"\\\\\"+PATH_FINAL_INVERTED_INDEX_DEBUG, \"r\") as file:\n",
    "        for line in file:\n",
    "            if (i==0): #In debug mode skip the first line.\n",
    "                i+=1\n",
    "                continue\n",
    "            term=line.split()[0]\n",
    "            postings_str_lst=line.split()[1:]\n",
    "\n",
    "            for posting in  postings_str_lst:\n",
    "                doc_id,freq=posting.split(\":\")\n",
    "                ind_read_from_disk.add_posting(term,int(doc_id),int(freq))\n",
    "            i+=1\n",
    "    \n",
    "    assert len(ind_read_from_disk.get_postings(\"is\"))==8 \n",
    "    assert ind_read_from_disk.get_postings(\"is\")[2].doc_id==3 and ind_read_from_disk.get_postings(\"is\")[2].frequency==1\n",
    "    assert ind_read_from_disk.get_postings(\"is\")[7].doc_id==14 and ind_read_from_disk.get_postings(\"is\")[7].frequency==2\n",
    "\n",
    "    assert len(ind_read_from_disk.get_postings(\"python\"))==1 \n",
    "    assert ind_read_from_disk.get_postings(\"python\")[0].doc_id==1 and ind_read_from_disk.get_postings(\"python\")[0].frequency==1\n",
    "\n",
    "    assert len(ind_read_from_disk.get_postings(\"the\"))==5 \n",
    "    assert ind_read_from_disk.get_postings(\"the\")[4].doc_id==9 and ind_read_from_disk.get_postings(\"the\")[4].frequency==4\n",
    "\n",
    "    assert len(ind_read_from_disk.get_postings(\"friendship\"))==1 \n",
    "    assert ind_read_from_disk.get_postings(\"friendship\")[0].doc_id==12\n",
    "    assert ind_read_from_disk.get_postings(\"friendship\")[0].frequency==1\n",
    "    \n",
    "    \n",
    "    if os.path.exists(DIR_LEXICON):\n",
    "        shutil.rmtree(DIR_LEXICON)\n",
    "                \n",
    "    if os.path.exists(DIR_INVERTED_INDEX):\n",
    "        shutil.rmtree(DIR_INVERTED_INDEX)\n",
    "    \n",
    "    if os.path.exists(DIR_DOC_INDEX):\n",
    "        shutil.rmtree(DIR_DOC_INDEX)\n",
    "    \n",
    "    if os.path.exists(DIR_TEMP_FOLDER):\n",
    "        shutil.rmtree(DIR_TEMP_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9944add6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.02s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest\n",
    "\n",
    "#Check if the datastructure contains the correct informations\n",
    "test_documents=[\n",
    "    \"doc_0\\t this is a random sentence without punctuation\",\n",
    "    \"doc_1\\t python is a versatile programming language\",\n",
    "    \"doc_2\\t the quick brown fox jumps over the lazy dog\"\n",
    "\n",
    "]\n",
    "#Here using the previous data structure to check if using spimi + merging it obtains the same result.\n",
    "def test_correctness_of_spimi_plus_merging_with_multiple_block_size_content_of_index():\n",
    "    \n",
    "    #I care to reset it because it has been decided to be defined as singleton...\n",
    "    docI=DocumentIndex()\n",
    "    docI.number_of_documents=0\n",
    "    docI.total_document_length=0\n",
    "    \n",
    "    indexBuilder=IndexBuilder(True,False,Collection_Reader(\"\",-1,-1,False,False,test_documents))\n",
    "    indexBuilder.single_pass_in_memory_indexing(500)\n",
    "    indexBuilder.index_merging()\n",
    "    \n",
    "    \n",
    "    ind_read_from_disk=InvertedIndex()\n",
    "    \n",
    "    i=0\n",
    "    with open(DIR_INVERTED_INDEX+\"\\\\\"+PATH_FINAL_INVERTED_INDEX_DEBUG, \"r\") as file:\n",
    "        for line in file:\n",
    "            if (i==0): #In debug mode skip the first line.\n",
    "                i+=1\n",
    "                continue\n",
    "            term=line.split()[0]\n",
    "            postings_str_lst=line.split()[1:]\n",
    "\n",
    "            for posting in  postings_str_lst:\n",
    "                doc_id,freq=posting.split(\":\")\n",
    "                ind_read_from_disk.add_posting(term,int(doc_id),int(freq))\n",
    "            i+=1\n",
    "    \n",
    "    assert len(ind_read_from_disk.get_postings(\"is\"))==2 \n",
    "    assert ind_read_from_disk.get_postings(\"is\")[1].doc_id==1 and ind_read_from_disk.get_postings(\"is\")[1].frequency==1\n",
    "\n",
    "    assert len(ind_read_from_disk.get_postings(\"python\"))==1 \n",
    "    assert ind_read_from_disk.get_postings(\"python\")[0].doc_id==1 and ind_read_from_disk.get_postings(\"python\")[0].frequency==1\n",
    "\n",
    "    assert len(ind_read_from_disk.get_postings(\"the\"))==1 \n",
    "    assert ind_read_from_disk.get_postings(\"the\")[0].doc_id==2 and ind_read_from_disk.get_postings(\"the\")[0].frequency==2\n",
    "\n",
    "    #Check if document statistic contains the right number of values\n",
    "    path_coll_stat=os.path.join(DIR_DOC_INDEX,PATH_COLLECTION_STATISTICS_DEBUG)\n",
    "    \n",
    "    lines_read=[]\n",
    "    with open(path_coll_stat, \"r\") as file:\n",
    "        for line in file:\n",
    "            lines_read.append(line)\n",
    "    \n",
    "    expected_output=[\"Document Index Size: 3\\n\",\"Vocabulary Size: 19\\n\",\"Sum Document length: 22\\n\"]\n",
    "    \n",
    "    for line,exp_output in zip(lines_read,expected_output):\n",
    "        assert line==exp_output\n",
    "    \n",
    "    #Check if document index contains the right informations\n",
    "    path_doc_index=os.path.join(DIR_DOC_INDEX,PATH_FINAL_DOCUMENT_INDEX_DEBUG)\n",
    "    \n",
    "    lines_read=[]\n",
    "    with open(path_doc_index, \"r\") as file:\n",
    "        for line in file:\n",
    "            lines_read.append(line)\n",
    "    \n",
    "    expected_output=[\"0 doc_0                          7\\n\",\"1 doc_1                          6\\n\",\"2 doc_2                          9\\n\"]\n",
    "    \n",
    "    for line,exp_output in zip(lines_read,expected_output):\n",
    "        assert line==exp_output\n",
    "    \n",
    "    #Check if lexicon contains the right informations\n",
    "    \n",
    "    \n",
    "    #TODO!!!!!\n",
    "    \n",
    "    \n",
    "    \n",
    "    if os.path.exists(DIR_LEXICON):\n",
    "        shutil.rmtree(DIR_LEXICON)\n",
    "                \n",
    "    if os.path.exists(DIR_INVERTED_INDEX):\n",
    "        shutil.rmtree(DIR_INVERTED_INDEX)\n",
    "    \n",
    "    if os.path.exists(DIR_DOC_INDEX):\n",
    "        shutil.rmtree(DIR_DOC_INDEX)\n",
    "    \n",
    "    if os.path.exists(DIR_TEMP_FOLDER):\n",
    "        shutil.rmtree(DIR_TEMP_FOLDER)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39e19904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.13s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest\n",
    "test_documents=[\n",
    "    \"0\\t this is a random sentence without punctuation\",\n",
    "    \"1\\t python is a versatile programming language\",\n",
    "    \"2\\t the quick brown fox jumps over the lazy dog\",\n",
    "    \"3\\t coding is a creative and logical process\",\n",
    "    \"4\\t sunsets are a beautiful sight to behold\",\n",
    "    \"5\\t coffee is a popular beverage around the world\",\n",
    "    \"6\\t music has the power to evoke emotions\",\n",
    "    \"7\\t books transport readers to different worlds\",\n",
    "    \"8\\t kindness and compassion make the world better\",\n",
    "    \"9\\t the moonlight reflects on the calm lake in the night the vision is awesome\",\n",
    "    \"10\\t nature provides solace and tranquility\",\n",
    "    \"11\\t imagination knows no boundaries\",\n",
    "    \"12\\t friendship is a treasure worth cherishing\",\n",
    "    \"13\\t happiness is found in simple moments\",\n",
    "    \"14\\t laughter is contagious and brings joy is better for all\"\n",
    "]\n",
    "\n",
    "#Test if it works with different block size.\n",
    "def test_correctness_of_spimi_plus_merging_with_multiple_block_size_content_of_index_with_different_blocks_size():\n",
    "    \n",
    "    #At each iteration it is aspected to obtain the same result for every possibile block size.\n",
    "    for i in range(1,6):   #Test for different block size\n",
    "\n",
    "        indexBuilder=IndexBuilder(True,False,Collection_Reader(\"\",-1,-1,False,False,test_documents))\n",
    "        indexBuilder.single_pass_in_memory_indexing(500*i)\n",
    "        indexBuilder.index_merging()\n",
    "\n",
    "        ind_read_from_disk=InvertedIndex()\n",
    "\n",
    "        i=0\n",
    "        with open(DIR_INVERTED_INDEX+\"\\\\\"+PATH_FINAL_INVERTED_INDEX_DEBUG, \"r\") as file:\n",
    "            for line in file:\n",
    "                if (i==0): #In debug mode skip the first line.\n",
    "                    i+=1\n",
    "                    continue\n",
    "                term=line.split()[0]\n",
    "                postings_str_lst=line.split()[1:]\n",
    "\n",
    "                for posting in  postings_str_lst:\n",
    "                    doc_id,freq=posting.split(\":\")\n",
    "                    ind_read_from_disk.add_posting(term,int(doc_id),int(freq))\n",
    "                i+=1\n",
    "\n",
    "        assert len(ind_read_from_disk.get_postings(\"is\"))==8 \n",
    "        assert ind_read_from_disk.get_postings(\"is\")[2].doc_id==3 and ind_read_from_disk.get_postings(\"is\")[2].frequency==1\n",
    "        assert ind_read_from_disk.get_postings(\"is\")[7].doc_id==14 and ind_read_from_disk.get_postings(\"is\")[7].frequency==2\n",
    "\n",
    "        assert len(ind_read_from_disk.get_postings(\"python\"))==1 \n",
    "        assert ind_read_from_disk.get_postings(\"python\")[0].doc_id==1 and ind_read_from_disk.get_postings(\"python\")[0].frequency==1\n",
    "\n",
    "        assert len(ind_read_from_disk.get_postings(\"the\"))==5 \n",
    "        assert ind_read_from_disk.get_postings(\"the\")[4].doc_id==9 and ind_read_from_disk.get_postings(\"the\")[4].frequency==4\n",
    "\n",
    "        assert len(ind_read_from_disk.get_postings(\"friendship\"))==1 \n",
    "        assert ind_read_from_disk.get_postings(\"friendship\")[0].doc_id==12\n",
    "        assert ind_read_from_disk.get_postings(\"friendship\")[0].frequency==1\n",
    "        \n",
    "    if os.path.exists(DIR_LEXICON):\n",
    "        shutil.rmtree(DIR_LEXICON)\n",
    "                \n",
    "    if os.path.exists(DIR_INVERTED_INDEX):\n",
    "        shutil.rmtree(DIR_INVERTED_INDEX)\n",
    "    \n",
    "    if os.path.exists(DIR_DOC_INDEX):\n",
    "        shutil.rmtree(DIR_DOC_INDEX)\n",
    "    \n",
    "    if os.path.exists(DIR_TEMP_FOLDER):\n",
    "        shutil.rmtree(DIR_TEMP_FOLDER)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
