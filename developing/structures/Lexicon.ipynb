{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2e21d95-98d7-45f1-937f-b59f775699bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from C:\\Users\\Davide\\IR\\Progetto\\structures\\..\\structures\\LexiconRow.ipynb\n",
      "importing Jupyter notebook from C:\\Users\\Davide\\IR\\Progetto\\structures\\..\\structures\\DocumentIndex.ipynb\n",
      "importing Jupyter notebook from C:\\Users\\Davide\\IR\\Progetto\\structures\\..\\utilities\\General_Utilities.ipynb\n",
      "importing Jupyter notebook from C:\\Users\\Davide\\IR\\Progetto\\structures\\..\\structures\\DocumentIndexRow.ipynb\n",
      "importing Jupyter notebook from C:\\Users\\Davide\\IR\\Progetto\\structures\\..\\building_data_structures\\CollectionStatistics.ipynb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import struct\n",
    "\n",
    "import math\n",
    "from collections import defaultdict, Counter\n",
    "from collections import OrderedDict\n",
    "from typing import List, TextIO, BinaryIO\n",
    "\n",
    "import import_ipynb\n",
    "import sys\n",
    "sys.path.append('../')  # Go up two folders to the project root\n",
    "\n",
    "from structures.LexiconRow import LexiconRow\n",
    "from structures.DocumentIndex import DocumentIndex\n",
    "from utilities.General_Utilities import Singleton\n",
    "from building_data_structures.CollectionStatistics import Collection_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5126ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lexicon:    \n",
    "    def __init__(self, capacity:int,path_lexicon:str=\"../building_data_structures/LEXICON/lexicon.bin\",path_collection_statistic:str=\"../building_data_structures/DOC_INDEX/collection_statistics.bin\"):\n",
    "        self.capacity = capacity\n",
    "        self._vocabulary = OrderedDict()\n",
    "        \n",
    "        \n",
    "        self.collectionStatistics = Collection_statistics(path_collection_statistic)\n",
    "        self.collectionStatistics.read_binary_mode()\n",
    "        \n",
    "        #This open just one time the lexicon file specified\n",
    "        self.file_lexicon=open(path_lexicon, 'rb')\n",
    "        \n",
    "\n",
    "    def add_term(self, lex_row: LexiconRow) -> None:\n",
    "        if lex_row.term not in self._vocabulary:\n",
    "            if len(self._vocabulary) >= self.capacity:\n",
    "                self._vocabulary.popitem(last=False) # delete less recent element\n",
    "\n",
    "            self._vocabulary[lex_row.term] = lex_row\n",
    "\n",
    "    def get_terms(self, term: str) -> LexiconRow:\n",
    "        \"\"\"Fetches a row to the lexicon\"\"\"\n",
    "        return self._vocabulary.get(term, None)\n",
    "\n",
    "    def is_empty(self)->bool:\n",
    "        \"\"\"Check if there is no term in the lexicon.\"\"\"\n",
    "        return len(self.get_structure())==0\n",
    "\n",
    "    def clear_structure(self):\n",
    "        \"\"\" It clears the lexicon data structure.\"\"\"\n",
    "        self._vocabulary.clear()\n",
    "    \n",
    "    def get_structure(self):\n",
    "        \"\"\"Returns the lexicon data structure.\"\"\"\n",
    "        return self._vocabulary \n",
    "    \n",
    "    def close_file(self):\n",
    "        \"\"\"Closes the opened lexicon file.\"\"\"\n",
    "        self.file_lexicon.close()\n",
    "\n",
    "    def find_entry(self,term: str) -> LexiconRow:\n",
    "        \"\"\"Perform binary search to find a lexicon entry for a given term.\n",
    "\n",
    "        Args:\n",
    "            term: The term to search for in the lexicon.\n",
    "    \n",
    "        Returns:\n",
    "            The LexiconRow object if the term is found, otherwise None.\n",
    "        \"\"\"\n",
    "        entry = LexiconRow(\"\",0)  \n",
    "        start = 0 \n",
    "        \n",
    "        # \"end\" is equal (at the beginning) to the total number of distinct terms in the lexicon\n",
    "        end = self.collectionStatistics.num_distinct_terms - 1  \n",
    "    \n",
    "        while start <= end:\n",
    "            mid = start + (end - start) // 2\n",
    "            \n",
    "            # Get entry from disk\n",
    "            entry.read_lexicon_row_on_disk_from_opened_file(self.file_lexicon, mid * entry.SIZE_LEXICON_ROW_FINAL)\n",
    "            key = entry.term.strip()\n",
    "            \n",
    "            # Check if the search was successful\n",
    "            if key == term:\n",
    "                return entry\n",
    "    \n",
    "            # Update search portion parameters\n",
    "            if term > key:\n",
    "                start = mid + 1\n",
    "            else:\n",
    "                end = mid - 1\n",
    "    \n",
    "        return None\n",
    "\n",
    "    def get_entry(self, term: str) -> LexiconRow:\n",
    "        entry = self.get_terms(term) # check if term is in cache\n",
    "        if entry is not None:\n",
    "            return entry\n",
    "            \n",
    "        entry = self.find_entry(term)\n",
    "        \n",
    "        if entry is not None:         # add to cache\n",
    "            self.add_term(entry)\n",
    "        \n",
    "        return entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c961989-3442-41ba-b8ae-71a77afea01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('happiness                     ', <structures.LexiconRow.LexiconRow object at 0x0000021E87324810>)])\n",
      "\n",
      "\n",
      "OrderedDict([('happiness                     ', <structures.LexiconRow.LexiconRow object at 0x0000021E87324810>), ('dog                           ', <structures.LexiconRow.LexiconRow object at 0x0000021E86DE4F90>)])\n",
      "\n",
      "\n",
      "OrderedDict([('dog                           ', <structures.LexiconRow.LexiconRow object at 0x0000021E86DE4F90>), ('cat                           ', <structures.LexiconRow.LexiconRow object at 0x0000021E8716D210>)])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Esempio di utilizzo:\n",
    "# vocabulary_cache = Lexicon(2)\n",
    "# vocabulary_cache.get_entry(\"happiness\")\n",
    "# print(vocabulary_cache.get_structure())\n",
    "# print(\"\\n\")\n",
    "\n",
    "# vocabulary_cache.get_entry(\"dog\")\n",
    "# print(vocabulary_cache.get_structure())\n",
    "# print(\"\\n\")\n",
    "\n",
    "# vocabulary_cache.get_entry(\"cat\")\n",
    "# print(vocabulary_cache.get_structure())\n",
    "# print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
