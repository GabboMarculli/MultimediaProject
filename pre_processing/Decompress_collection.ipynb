{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7104e7ab-9d07-43de-82c0-5061dfb7f246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from C:\\Users\\gabri\\Documents\\GitHub\\MultimediaProject\\pre_processing\\..\\pre_processing\\TextProcessor.ipynb\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import io\n",
    "import tarfile\n",
    "from tarfile import TarInfo\n",
    "import threading\n",
    "\n",
    "import sys\n",
    "import import_ipynb\n",
    "\n",
    "from typing import TextIO, BinaryIO\n",
    "from typing import List\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "import pre_processing.TextProcessor as text_proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83a7c96d-5929-41df-8a87-a8ad83a85a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_compressed_tsv_line_by_line(compressed_file_path):\n",
    "    try:\n",
    "        with open(compressed_file_path, 'rb') as f:\n",
    "            text_processor = TextProcessor()\n",
    "            with gzip.GzipFile(fileobj=f) as gz: \n",
    "                buffer = io.TextIOWrapper(gz, encoding='utf-8')\n",
    "\n",
    "                # C'è bisogno di leggere la prima riga a parte perchè essa inizia con i seguenti metadati \"# collection.tsv0000777000175000017502663675055413400073633015704 0ustar  spacemanidolspacemanidol0 \"\n",
    "                # Quindi prima di entrare nel ciclo che legge tutte le righe, elimino questo prefisso\n",
    "                first_line = next(buffer)  # Leggi la prima riga\n",
    "                cleaned_first_line = ' '.join(first_line.split()[3:])  # Rimuovi la parte iniziale indesiderata\n",
    "                text_processor.process_text(text)(0, cleaned_first_line)\n",
    "\n",
    "                for line in buffer:\n",
    "                    pid, text = line.strip().split('\\t')\n",
    "                    text_processor.process_text(text)(pid, text)\n",
    "                    print(pid,text)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {compressed_file_path} non trovato.\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(f\"Si è verificato un errore durante l'analisi del file {compressed_file_path}: {e}\")\n",
    "\n",
    "# Esempio di utilizzo\n",
    "#parse_compressed_tsv_line_by_line('collection.tar.gz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "be6a68c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompress_strings(compressed_file_path):\n",
    "    try:\n",
    "        with open(compressed_file_path, 'rb') as f:\n",
    "            text_processor = TextProcessor()\n",
    "            with gzip.GzipFile(fileobj=f) as gz: \n",
    "                buffer = io.TextIOWrapper(gz, encoding='utf-8')\n",
    "                print(buffer)\n",
    "                # C'è bisogno di leggere la prima riga a parte perchè essa inizia con i seguenti metadati \"# collection.tsv0000777000175000017502663675055413400073633015704 0ustar  spacemanidolspacemanidol0 \"\n",
    "                # Quindi prima di entrare nel ciclo che legge tutte le righe, elimino questo prefisso\n",
    "                first_line = next(buffer)  # Leggi la prima riga\n",
    "                cleaned_first_line = ' '.join(first_line.split()[3:])  # Rimuovi la parte iniziale indesiderata\n",
    "                text_processor.process_text(text)(0, cleaned_first_line)\n",
    "\n",
    "                for line in buffer:\n",
    "                    pid, text = line.strip().split('\\t')\n",
    "                    text_processor.process_text(text)(pid, text)\n",
    "                    #print(pid,text)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {compressed_file_path} non trovato.\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(f\"Si è verificato un errore durante l'analisi del file {compressed_file_path}: {e}\")\n",
    "    \n",
    "    return decompressed_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b64dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifica il percorso del file TSV\n",
    "file_path = \"collection_cleaned.tsv\"\n",
    "with open(file_path, 'rb') as f:\n",
    "    count = 0\n",
    "    for line in f:\n",
    "        print(line)\n",
    "        count = count + 1\n",
    "        if count == 5:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15d19311-9b6f-48dc-805f-eb1ac7997285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'module' object is not callable\n",
      "Si è verificato un errore durante l'analisi del file C:/Users/Davide/IR/collection.tar.gz: 'module' object is not callable\n"
     ]
    }
   ],
   "source": [
    "parse_compressed_tsv_line_by_line(\"C:/Users/Davide/IR/collection.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acc5e51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Collection_Reader:\n",
    "    collection_file: tarfile.TarFile\n",
    "        \n",
    "    MEMORY_BASED_BUFFER_SIZE:int\n",
    "    memory_based_buffer:List[str]\n",
    "        \n",
    "    text_processor:text_proc.TextProcessor\n",
    "    file_position: int\n",
    "    file_members:List[TarInfo]\n",
    "    \n",
    "    def __init__(self,path_collection_file:str,memory_based_buffer_size:int):\n",
    "        \n",
    "        print(\"Init Collection Reader\")\n",
    "        \n",
    "        self.collection_file = tarfile.open(path_collection_file, 'r:gz')\n",
    "        self.MEMORY_BASED_BUFFER_SIZE = memory_based_buffer_size\n",
    "        self.text_processor = text_proc.TextProcessor(True, True)\n",
    "        self.file_position = 0\n",
    "        self.memory_based_buffer = []\n",
    "        self.file_member = self.collection_file.getmembers()[0]\n",
    "\n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "    def read_collection(self):\n",
    "        print(\"Reading collection...\")        \n",
    "\n",
    "        # Leggi MEMORY_BASED_BUFFER_SIZE righe in un colpo dal membro corrente\n",
    "        with self.collection_file.extractfile(self.file_member) as file_handle:\n",
    "            file_handle.seek(self.file_position)\n",
    "            \n",
    "            for _ in range(self.MEMORY_BASED_BUFFER_SIZE):\n",
    "                line = file_handle.readline().decode('utf-8')\n",
    "    \n",
    "                # end of file\n",
    "                if not line:\n",
    "                    break \n",
    "                    \n",
    "                line_processed = self.text_processor.process_text(line)\n",
    "                self.memory_based_buffer.append(line_processed)\n",
    "\n",
    "                self.file_position = file_handle.tell()\n",
    "\n",
    "    def read_collection_threaded(self):\n",
    "       with self.lock:\n",
    "           self.read_collection()\n",
    "    \n",
    "    def get_documents(self):\n",
    "        \"\"\" This is the only function to be called from outside to have a list of documents ready to be processed.\n",
    "        \n",
    "        Returns:\n",
    "           the memory_based_buffer list of strings\n",
    "            \n",
    "        \"\"\"\n",
    "        self.memory_based_buffer.clear()\n",
    "\n",
    "        # Start thread to read next block\n",
    "        thread = threading.Thread(target=self.read_collection_threaded)\n",
    "        thread.start()\n",
    "\n",
    "        # Waiting for the end of reading\n",
    "        thread.join()\n",
    "        \n",
    "        return self.memory_based_buffer\n",
    "    \n",
    "    \n",
    "    \n",
    "    def close_file_collection(self):\n",
    "        collection_file.close()\n",
    "         \n",
    "#Qua potrebbe essere utile pensare di farlo con 2 thread.\n",
    "#Quando viene chiamata la funzione get_documents, si restituisce al chiamante il blocco di documenti richiesti\n",
    "#e nel mentre si potrebbe attivare un thread che parallelamente carica il successivo blocco di documenti e lo\n",
    "#salva localmente nella struttura dati, quindi alla prossima chiamata get_documents ho già pronto il blocco e non\n",
    "# devo stare ad aspettare tutta la lettura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "156da327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Collection Reader\n",
      "Reading collection...\n",
      "Reading collection...\n",
      "5\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "startswith() takes at least 1 argument (0 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m document\u001b[38;5;241m.\u001b[39mstartswith(expected_prefix)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mstr\u001b[39m(i))\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdocument\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstartswith\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# print(block_2)\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: startswith() takes at least 1 argument (0 given)"
     ]
    }
   ],
   "source": [
    "path = \"C:/Users/gabri/Desktop/Materie magistrale/Multimedia/progetto/collection.tar.gz\"\n",
    "reader = Collection_Reader(path, 5)\n",
    "# print(\"Primo blocco: \\n\")\n",
    "block_0 = reader.get_documents()\n",
    "\n",
    "assert len(block_0) == reader.MEMORY_BASED_BUFFER_SIZE\n",
    "assert block_0[2] == '2 essay manhattan project manhattan project manhattan project see make atom bomb possibl success project would forev chang world forev make known someth power manmad'\n",
    "# print(block_0)\n",
    "\n",
    "# print(\"Secondo blocco: \\n\")\n",
    "block_2 = reader.get_documents()\n",
    "\n",
    "for i, document in enumerate(block_2, start=5):\n",
    "    expected_prefix = str(i)\n",
    "    assert document.startswith(expected_prefix)\n",
    "    \n",
    "# print(block_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074fb8a2-7980-4012-85a7-32212e8441dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
