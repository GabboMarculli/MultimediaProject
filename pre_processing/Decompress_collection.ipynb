{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7104e7ab-9d07-43de-82c0-5061dfb7f246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from C:\\Users\\Davide\\IR\\Progetto\\pre_processing\\..\\pre_processing\\TextProcessor.ipynb\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import io\n",
    "\n",
    "import sys\n",
    "import import_ipynb\n",
    "\n",
    "from typing import TextIO, BinaryIO\n",
    "from typing import List\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from pre_processing import TextProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83a7c96d-5929-41df-8a87-a8ad83a85a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_compressed_tsv_line_by_line(compressed_file_path):\n",
    "    try:\n",
    "        with open(compressed_file_path, 'rb') as f:\n",
    "            text_processor = TextProcessor()\n",
    "            with gzip.GzipFile(fileobj=f) as gz: \n",
    "                buffer = io.TextIOWrapper(gz, encoding='utf-8')\n",
    "\n",
    "                # C'è bisogno di leggere la prima riga a parte perchè essa inizia con i seguenti metadati \"# collection.tsv0000777000175000017502663675055413400073633015704 0ustar  spacemanidolspacemanidol0 \"\n",
    "                # Quindi prima di entrare nel ciclo che legge tutte le righe, elimino questo prefisso\n",
    "                first_line = next(buffer)  # Leggi la prima riga\n",
    "                cleaned_first_line = ' '.join(first_line.split()[3:])  # Rimuovi la parte iniziale indesiderata\n",
    "                text_processor.process_text(text)(0, cleaned_first_line)\n",
    "\n",
    "                for line in buffer:\n",
    "                    pid, text = line.strip().split('\\t')\n",
    "                    text_processor.process_text(text)(pid, text)\n",
    "                    print(pid,text)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {compressed_file_path} non trovato.\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(f\"Si è verificato un errore durante l'analisi del file {compressed_file_path}: {e}\")\n",
    "\n",
    "# Esempio di utilizzo\n",
    "#parse_compressed_tsv_line_by_line('collection.tar.gz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "be6a68c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompress_strings(compressed_file_path):\n",
    "    try:\n",
    "        with open(compressed_file_path, 'rb') as f:\n",
    "            text_processor = TextProcessor()\n",
    "            with gzip.GzipFile(fileobj=f) as gz: \n",
    "                buffer = io.TextIOWrapper(gz, encoding='utf-8')\n",
    "                print(buffer)\n",
    "                # C'è bisogno di leggere la prima riga a parte perchè essa inizia con i seguenti metadati \"# collection.tsv0000777000175000017502663675055413400073633015704 0ustar  spacemanidolspacemanidol0 \"\n",
    "                # Quindi prima di entrare nel ciclo che legge tutte le righe, elimino questo prefisso\n",
    "                first_line = next(buffer)  # Leggi la prima riga\n",
    "                cleaned_first_line = ' '.join(first_line.split()[3:])  # Rimuovi la parte iniziale indesiderata\n",
    "                text_processor.process_text(text)(0, cleaned_first_line)\n",
    "\n",
    "                for line in buffer:\n",
    "                    pid, text = line.strip().split('\\t')\n",
    "                    text_processor.process_text(text)(pid, text)\n",
    "                    #print(pid,text)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {compressed_file_path} non trovato.\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(f\"Si è verificato un errore durante l'analisi del file {compressed_file_path}: {e}\")\n",
    "    \n",
    "    return decompressed_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b64dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifica il percorso del file TSV\n",
    "file_path = \"collection_cleaned.tsv\"\n",
    "with open(file_path, 'rb') as f:\n",
    "    count = 0\n",
    "    for line in f:\n",
    "        print(line)\n",
    "        count = count + 1\n",
    "        if count == 5:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15d19311-9b6f-48dc-805f-eb1ac7997285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'module' object is not callable\n",
      "Si è verificato un errore durante l'analisi del file C:/Users/Davide/IR/collection.tar.gz: 'module' object is not callable\n"
     ]
    }
   ],
   "source": [
    "parse_compressed_tsv_line_by_line(\"C:/Users/Davide/IR/collection.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acc5e51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Collection_Reader:\n",
    "    \n",
    "    collection_file:BinaryIO\n",
    "        \n",
    "    MEMORY_BASED_BUFFER_SIZE:int\n",
    "    memory_based_buffer:List[str]\n",
    "        \n",
    "    text_processor:TextProcessor\n",
    "    \n",
    "    def __init__(self,path_collection_file:str,memory_based_buffer_size:int):\n",
    "        \n",
    "        print(\"Init Collection Reader\")\n",
    "        \n",
    "        self.collection_file=open(path_collection_file, 'rb')\n",
    "        self.MEMORY_BASED_BUFFER_SIZE=memory_based_buffer_size\n",
    "        \n",
    "        self.text_processor=TextProcessor()\n",
    "        \n",
    "        #Todo, qua aggiustarsi il caso che la collection abbia la prima riga composta da informazioni da scartare.\n",
    "        \n",
    "\n",
    "    def _read_collection(self):\n",
    "        print(\"todo\")\n",
    "        #Todo\n",
    "        #Leggere un numero di righe pari alla dimensione memory_based_buffer \"in un colpo solo, quindi unica lettura\"\n",
    "        #eseguire quindi la decompressione dell'unico \"blocco di righe letto\"\n",
    "        #e salvarle dentro memory_based_buffer\n",
    "        \n",
    "    \n",
    "    \n",
    "    def get_documents(self):\n",
    "        \"\"\" This is the only function to be called from outside to have a list of documents ready to be processed.\n",
    "        \n",
    "        Returns:\n",
    "           the memory_based_buffer list of strings\n",
    "            \n",
    "        \"\"\"\n",
    "        memory_based_buffer.clear()\n",
    "        self.read_collection()\n",
    "        return memory_based_buffer\n",
    "    \n",
    "    \n",
    "    \n",
    "    def close_file_collection(self):\n",
    "        collection_file.close()\n",
    "         \n",
    "#Qua potrebbe essere utile pensare di farlo con 2 thread.\n",
    "#Quando viene chiamata la funzione get_documents, si restituisce al chiamante il blocco di documenti richiesti\n",
    "#e nel mentre si potrebbe attivare un thread che parallelamente carica il successivo blocco di documenti e lo\n",
    "#salva localmente nella struttura dati, quindi alla prossima chiamata get_documents ho già pronto il blocco e non\n",
    "# devo stare ad aspettare tutta la lettura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156da327",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
