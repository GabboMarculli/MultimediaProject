{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74ac7357-ff7e-4c72-824f-750cb92a57a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from C:\\Users\\gabri\\Documents\\GitHub\\MultimediaProject\\tests\\Building_Data_Structures\\../..\\building_data_structures\\Lexicon.ipynb\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import ipytest\n",
    "import import_ipynb\n",
    "import sys\n",
    "sys.path.append('../../')  # Go up two folders to the project root\n",
    "\n",
    "from building_data_structures.Lexicon import DocumentIndex, DocumentIndexRow, Lexicon, LexiconRow, create_lexicon\n",
    "\n",
    "ipytest.autoconfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e19a3370-7fc3-4765-bbe6-51eec74a6881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                                                           [100%]\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 0.01s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest\n",
    "\n",
    "def test_lexicon_structure():\n",
    "    voc = Lexicon()\n",
    "\n",
    "    # Create a doc index with 2 documents\n",
    "    doc = DocumentIndex()\n",
    "    doc.clear_structure()\n",
    "    doc.add_document(1, \"Information retrieval system\")\n",
    "    doc.add_document(2, \"Information retrieval project\")\n",
    "\n",
    "    # test on term \"information\"\n",
    "    voc.add_term(\"Information\", 2, doc, 1)\n",
    "    assert voc.get_terms(\"Information\").term == \"Information\"\n",
    "    assert voc.get_terms(\"Information\").dft == 2\n",
    "    assert voc.get_terms(\"Information\").max_tf == 1\n",
    "    assert voc.get_terms(\"Information\").idft == 0 # log(number of doc / dft)\n",
    "\n",
    "    # test on term \"system\"\n",
    "    voc.add_term(\"system\", 1, doc, 1)\n",
    "    assert voc.get_terms(\"system\").term == \"system\"\n",
    "    assert voc.get_terms(\"system\").dft == 1\n",
    "    assert voc.get_terms(\"system\").max_tf == 1\n",
    "    assert doc.number_of_documents == 2\n",
    "    assert round(voc.get_terms(\"system\").idft, 2) == 0.69 # log(number of doc / dft)\n",
    "\n",
    "    try:\n",
    "        voc.add_term(4, 2, doc, 1)\n",
    "    except ValueError as e:\n",
    "        assert str(e) == \"There's an error in parameter's type.\"\n",
    "\n",
    "    try:\n",
    "        voc.add_term(\"Retrieval\", \"Hello\", doc, 1)\n",
    "    except ValueError as e:\n",
    "        assert str(e) == \"There's an error in parameter's type.\"\n",
    "\n",
    "    try:\n",
    "        voc.get_terms(4567)\n",
    "    except ValueError as e:\n",
    "        assert str(e) == \"Term must be a string.\"\n",
    "    \n",
    "    voc_aux = voc.get_structure()\n",
    "    assert voc.get_terms(\"Information\")==voc_aux[\"Information\"]\n",
    "    \n",
    "    assert voc.is_empty() == False\n",
    "    voc.clear_structure()\n",
    "    assert voc.is_empty() == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b00f2089-5c66-4d97-960e-79b6a623edda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[33m\u001b[33mno tests ran\u001b[0m\u001b[33m in 0.01s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest\n",
    "\n",
    "# TESTO TO CREATE LEXICON\n",
    "valid_document_index = DocumentIndex()\n",
    "\n",
    "# Case 1: Valid parameters\n",
    "assert create_lexicon(\"complete_inverted_index.txt\", \"lexicon\", \"Lexicon/\", \".txt\", 2200, valid_document_index) != -1\n",
    "\n",
    "# Case 2: Invalid file_input_path (empty string)\n",
    "try:\n",
    "    create_lexicon(\"\", \"output/folder\", \"documents\", \".txt\", 10, valid_document_index)\n",
    "except ValueError as e:\n",
    "    assert str(e) == \"Invalid file_input_path.\"\n",
    "\n",
    "# Case 3: Invalid file_output_path (empty string)\n",
    "try:\n",
    "    create_lexicon(\"complete_inverted_index.txt\", \"\", \"Lexicon/\", \".txt\", 2200, valid_document_index)\n",
    "except ValueError as e:\n",
    "    assert str(e) == \"Invalid file_output_path.\"\n",
    "\n",
    "# Case 4: Invalid DIR_FOLDER (empty string)\n",
    "try:\n",
    "    create_lexicon(\"complete_inverted_index.txt\", \"lexicon\", \"\", \".txt\", 2200, valid_document_index)\n",
    "except ValueError as e:\n",
    "    assert str(e) == \"Invalid DIR_FOLDER.\"\n",
    "\n",
    "# Case 5: Invalid file_extension (empty string)\n",
    "try:\n",
    "    create_lexicon(\"complete_inverted_index.txt\", \"lexicon\", \"Lexicon/\", \"\", 2200, valid_document_index)\n",
    "except ValueError as e:\n",
    "    assert str(e) == \"Invalid file_extension.\"\n",
    "\n",
    "# Case 6: Invalid block_size (negative integer)\n",
    "try:\n",
    "    create_lexicon(\"complete_inverted_index.txt\", \"lexicon\", \"Lexicon/\", \".txt\", -5, valid_document_index)\n",
    "except ValueError as e:\n",
    "    assert str(e) == \"Invalid block_size. Must be a positive integer.\"\n",
    "\n",
    "# Case 7: Invalid document_index (not an instance of DocumentIndex)\n",
    "try:\n",
    "    create_lexicon(\"complete_inverted_index.txt\", \"lexicon\", \"Lexicon/\", \".txt\", 2200, \"invalid_document_index\")\n",
    "except ValueError as e:\n",
    "    assert str(e) == \"Invalid document_index. Must be an instance of DocumentIndex.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cfbbf18-99bf-4100-909d-630524c73c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[33m\u001b[33mno tests ran\u001b[0m\u001b[33m in 0.00s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest\n",
    "\n",
    "from building_data_structures.Lexicon import compute_max_term_frequency, compute_IDFT, compute_TFIDF, compute_avgDL, compute_BM25_term\n",
    "# TEST metrics\n",
    "\n",
    "# test compute max term frequency\n",
    "postings_list1 = \"3:2 5:2 9:1 10:1 14:1 17:1 21:1 25:1 27:1 36:1 51:1 56:1\"\n",
    "postings_list2 = \"3:10 5:2 9:3 10:1 14:1 17:2 21:1 25:1 27:1 36:1 51:1 56:9\"\n",
    "postings_list3 = \"3:2 5:2 9:5 10:1 14:1 17:1 21:5 25:1 27:6 36:1 51:8 56:1\"\n",
    "\n",
    "assert compute_max_term_frequency(postings_list1) == 2\n",
    "assert compute_max_term_frequency(postings_list2) == 10\n",
    "assert compute_max_term_frequency(postings_list3) == 8\n",
    "assert compute_max_term_frequency(\"\") == 0\n",
    "\n",
    "try:\n",
    "    compute_max_term_frequency(45)\n",
    "except ValueError as e:\n",
    "    assert str(e) == \"Invalid postings list.\"\n",
    "\n",
    "# test compute_IDFT\n",
    "assert valid_document_index.number_of_documents == 2\n",
    "assert compute_IDFT(valid_document_index.number_of_documents, 3) == -0.40546510810816444 # ln(2/3) == -0.40546510810816444\n",
    "assert compute_IDFT(valid_document_index.number_of_documents, 8) == -1.3862943611198906  # ln(2/8) == -1.3862943611198906\n",
    "assert compute_IDFT(valid_document_index.number_of_documents, 1) ==  0.6931471805599453  # ln(2)   ==  0.6931471805599453\n",
    "assert compute_IDFT(valid_document_index.number_of_documents, -5) == 0\n",
    "\n",
    "try:\n",
    "    compute_IDFT(\"invalid document index\", 3)\n",
    "except ValueError as e:\n",
    "    assert str(e) == \"Invalid parameters.\"\n",
    "\n",
    "try: \n",
    "    compute_IDFT(valid_document_index.number_of_documents, \"hello\")\n",
    "except ValueError as e:\n",
    "    assert str(e) == \"Invalid parameters.\"\n",
    "\n",
    "# test compute_TFIDF\n",
    "assert compute_TFIDF(3, -0.40546510810816444) == -0.8509140585019376 # (1 + math.log(3)) * -0.40546510810816444 = 2.0986122886681 * -0.40546510810816444\n",
    "assert compute_TFIDF(2, 0.6931471805599453)   ==  1.1736001944781467 # (1 + 0.69314718055995) * 0.6931471805599453 \n",
    "assert compute_TFIDF(-5, 0.245543234545434) == 0\n",
    "\n",
    "try:\n",
    "    compute_TFIDF(2, \"hello\")\n",
    "except ValueError as e:\n",
    "    assert str(e) == \"Invalid parameters.\"\n",
    "\n",
    "# test compute BM25\n",
    "# il document index in questo caso è fatto così:\n",
    "# (1, \"Information retrieval system\")\n",
    "# (2, \"Information retrieval project\")\n",
    "# PROVIAMO A CALCOLARE 1 SINGOLO CONTRIBUTO DELLA SOMMATORIA DEL BM25 DATO DA UNA QUERY COMPOSTA DAL SOLO TERMINE \"system\"\n",
    "# NEL NOSTRO CASO \"system\" COMPARE IN 1 DOCUMENTO, HA DFT=1\n",
    "log_tf = (1 + math.log(1)) # LA TERM FREQUENCIES DI \"system\" NEL DOCUMENTO CON DOC_ID = 1 è 1, COMPARE UNA SOLA VOLTA\n",
    "avgDL = compute_avgDL(valid_document_index) # LA LUNGHEZZA MEDIA DEI DOCUMENTI E' 3\n",
    "doc_len = valid_document_index.get_document(1).document_length # IL DOCUMENTO IN QUESTIONE E' COMPOSTO DA 3 TERMINI\n",
    "assert idf == 0.6931471805599453\n",
    "assert avgDL == 3\n",
    "assert log_tf == 1\n",
    "assert doc_len == 3\n",
    "assert float((idf * log_tf)/(log_tf + 1.6 * ( (1 - 0.75) + 0.75 * (doc_len/avgDL) ))) == 0.2665950694461328\n",
    "assert compute_BM25_term(valid_document_index, 1, idf, 1) == 0.2665950694461328\n",
    "\n",
    "# test compute_avgDL\n",
    "assert valid_document_index.total_document_length == 6\n",
    "assert valid_document_index.number_of_documents == 2\n",
    "\n",
    "assert compute_avgDL(valid_document_index) == 3\n",
    "\n",
    "try:\n",
    "    compute_avgDL(\"hello\")\n",
    "except ValueError as e:\n",
    "    assert str(e) == \"Invalid parameters.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
