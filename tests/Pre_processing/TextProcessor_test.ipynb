{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1ded6f5-4fae-4f7b-9df8-faa13a2e0fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from C:\\Users\\gabri\\Documents\\GitHub\\MultimediaProject\\tests\\Pre_processing\\../..\\pre_processing\\TextProcessor.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../')  # Go up two folders to the project root\n",
    "\n",
    "from pre_processing.TextProcessor import TextProcessor "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563dc4e4-cbfd-4618-bad2-27f0f08d75b6",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7214437a-ad76-40a7-99c1-b37be0f85aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "import ipytest\n",
    "\n",
    "ipytest.autoconfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ed96b42-8ad7-4f08-9c15-b316183794c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[33m\u001b[33mno tests ran\u001b[0m\u001b[33m in 0.01s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest\n",
    "\n",
    "\n",
    "#Text process test without steamming and stop words.\n",
    "'''\n",
    "@pytest.mark.parametrize(\"test_sentences,expected_results\", list(zip(TEST_SENTENCES,EXPECTED_SENTENCES_WITHOUT_STEMMING_AND_STOP_WORDS)))\n",
    "def test_eval(test_sentences:str, expected_results:str):\n",
    "    text_processor = TextProcessor(False,False) \n",
    "    ris=text_processor.process_text(test_sentences)\n",
    "    print (ris)\n",
    "    print (\"----\")\n",
    "    print (expected_results)\n",
    "    assert ris == expected_results\n",
    "'''\n",
    "    \n",
    "#TODO ripeti la stessa procedura fatta ma con un array specifico in cui controlli anche lo steamming e  un altro a parte per le stop word (oppure fanne uno unico insieme valuta te)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "091567c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                                                          [100%]\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m3 passed\u001b[0m\u001b[32m in 1.63s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest\n",
    "\n",
    "# test without stemming and stopword\n",
    "proc = TextProcessor(False, False)\n",
    "\n",
    "TEST_SENTENCES=[\n",
    "    \"This is a sentence with multiple spaces  and punctuation!\",\n",
    "    \"https://en.wikipedia.org/wiki/List_of_Unicode_characters ciao\",\n",
    "    \"The first websiteâThe Manhattan Project:\",\n",
    "    \"Each of these types of communitiesâ <html> prova </html>\",\n",
    "    \"There are special characters like @, #, $, %, and ^ in this sentence.\",\n",
    "    \"\",\n",
    "    \"      .................   !!!!!! @#&                    \",\n",
    "    \" !%£&/  ($£(/  £()\",\n",
    "    \"The $sun is shining! brightly                  ..... in the sky&&.\"\n",
    "]\n",
    "\n",
    "EXPECTED_SENTENCES_WITHOUT_STEMMING_AND_STOP_WORDS =[\n",
    "    \"this is a sentence with multiple spaces and punctuation\",\n",
    "    \"ciao\",\n",
    "    \"the first website the manhattan project\",\n",
    "    \"each of these types of communities prova\",\n",
    "    \"there are special characters like and in this sentence\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"the sun is shining brightly in the sky\"\n",
    "]\n",
    "\n",
    "anotherLanguage = [\n",
    "    \"Questa è una frase con spazi multipli e punteggiatura!\",               # In italian\n",
    "    \"https://it.wikipedia.org/wiki/Elenco_dei_caratteri_Unicode ciao\",\n",
    "    \"Il primo sito webâIl Progetto Manhattan:\",\n",
    "    \"Ognuno di questi tipi di comunitàâ <html> prova </html>\",\n",
    "    \"Ci sono caratteri speciali come @, #, $, % e ^ in questa frase.\",\n",
    "]\n",
    "\n",
    "expected_sentences = [\n",
    "    \"questa una frase con spazi multipli e punteggiatura\",\n",
    "    \"ciao\",\n",
    "    \"il primo sito web il progetto manhattan\",\n",
    "    \"ognuno di questi tipi di comunit prova\",\n",
    "    \"ci sono caratteri speciali come e in questa frase\",\n",
    "]\n",
    "\n",
    "def test_without_flags():\n",
    "    for i in range(0, len(TEST_SENTENCES)): # english\n",
    "        assert proc.process_text(TEST_SENTENCES[i]) == EXPECTED_SENTENCES_WITHOUT_STEMMING_AND_STOP_WORDS[i]\n",
    "        \n",
    "    for i in range(0, len(anotherLanguage)): # italian\n",
    "        assert proc.process_text(anotherLanguage[i]) == expected_sentences[i]\n",
    "\n",
    "# WITH STOP WORDS REMOVING AND STEMMING\n",
    "import re\n",
    "text_processor = TextProcessor(use_stemming=True, use_stopwords=True)\n",
    "\n",
    "def test_single_functionalities():\n",
    "    # Test for regexp\n",
    "    assert re.sub(text_processor.reg_exp_html_tags, \"\", \"<html>This is an <b>example</b> text.</html>\") == \"This is an example text.\"\n",
    "    assert re.sub(text_processor.reg_exp_usernames, \"\", \"Hello @user123, how are you?\") == \"Hello , how are you?\"\n",
    "    assert re.sub(text_processor.reg_exp_web_link_pattern, \"\", \"Visit our website: https://www.example.com\") == \"Visit our website: \"\n",
    "    assert re.sub(text_processor.reg_exp_punctuation, \"\", \"This is a sentence with @ special characters!\") == \"This is a sentence with  special characters\"\n",
    "    \n",
    "    # Test for stemming and stopword in english, italin and spanish\n",
    "    assert text_processor.stem_text([\"running\", \"jumped\", \"swimming\"], \"english\") == [\"run\", \"jump\", \"swim\"]\n",
    "    assert text_processor.remove_stopwords([\"this\", \"is\", \"a\", \"test\"], \"english\") == [\"test\"]\n",
    "    assert text_processor.stem_text([\"programmazione\", \"divertente\", \"complicata\"], \"italian\") == [\"programm\", \"divertent\", \"complic\"]\n",
    "    assert text_processor.remove_stopwords([\"questo\", \"è\", \"un\", \"test\"], \"italian\") == [\"test\"]\n",
    "    assert text_processor.stem_text([\"programación\", \"divertida\", \"complicada\"], \"spanish\") == [\"program\", \"divert\", \"complic\"]\n",
    "    assert text_processor.remove_stopwords([\"esto\", \"es\", \"una\", \"prueba\"], \"spanish\") == [\"prueba\"]\n",
    "\n",
    "EXPECTED_SENTENCES_WITH_STEMMING_AND_STOP_WORDS =[   # test in english\n",
    "    \"sentenc multipl space punctuat\",\n",
    "    \"cia\",\n",
    "    \"first websit manhattan project\",\n",
    "    \"type communiti prova\",\n",
    "    \"special charact like sentenc\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"sun shine bright sky\",\n",
    "]\n",
    "\n",
    "expected_sentences_with_stemming_and_stop_words = [    # test in italian\n",
    "    \"fras spaz multipl punteggiatur\",\n",
    "    \"cia\",\n",
    "    \"prim sit web progett manhattan\",\n",
    "    \"ognun tip comunit prov\",\n",
    "    \"caratter special fras\"\n",
    "]\n",
    "\n",
    "def test_with_flags():\n",
    "    for i in range(0, len(TEST_SENTENCES)):\n",
    "        assert text_processor.process_text(TEST_SENTENCES[i]) == EXPECTED_SENTENCES_WITH_STEMMING_AND_STOP_WORDS[i]\n",
    "    \n",
    "    for i in range(0, len(expected_sentences_with_stemming_and_stop_words)):\n",
    "        assert text_processor.process_text(anotherLanguage[i]) == expected_sentences_with_stemming_and_stop_words[i]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
